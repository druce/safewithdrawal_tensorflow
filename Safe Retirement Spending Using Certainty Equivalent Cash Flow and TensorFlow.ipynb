{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safe Retirement Spending Using Certainty Equivalent Cash Flow and Tensorflow\n",
    "\n",
    "TensorFlow code to find a retirement spending strategy that would have optimized certainty equivalent cash flow over all 30-year historical retirement cohorts, 1928-1986.\n",
    "\n",
    "To calculate CE cash flow, first calculate CRRA utility for a retiree's cash flows and risk aversion parameter &gamma; (gamma):\n",
    "\n",
    "$$U=\\frac{1}{n}\\sum_{i}\\frac{C_i^{1-\\gamma}-1}{1-\\gamma}$$\n",
    "\n",
    "Then convert average CRRA utility back to a cash flow equivalent using the inverse function.\n",
    "\n",
    "$$CE = [U(1-\\gamma) + 1] ^ {\\frac{1}{1-\\gamma}}$$\n",
    "\n",
    " - γ = 0 means you’re risk neutral. There is no discount, however variable or uncertain the cash flows. The CE value equals the average of the cash flows.\n",
    " - γ = 8 means you’re fairly risk averse. The CE value reflects a large discount vs. the average cash flow.\n",
    " - The higher the variability of the cash flows, the greater the discount. And the higher the γ parameter, the greater the discount.\n",
    " \n",
    "We model retirement cash flows as a function of:\n",
    "\n",
    " - Constant spending (a single value): A constant inflation-adjusted amount you withdraw each year in retirement. This is like the 4% in Bengen’s 4% rule. The inflation-adjusted value of this annual withdrawal never changes.\n",
    " - Variable spending (30 values, one for each year, i.e. a list or vector): A variable percentage of your portfolio value you withdraw each year. In contrast to the Bengen 4% rule, we’re, saying, if the portfolio appreciates, you can safely withdraw an additional amount based on the current value of the portfolio. Your total spending is the sum of 1) constant spending and 2) variable spending * portfolio value.\n",
    " - Stock allocation (30 values, one for each year): We study a portfolio with 2 assets: S&P 500 stocks and 10-year Treasurys. Bond allocation = 1 - stock allocation.\n",
    " \n",
    "Using these variables, we construct a TensorFlow graph.\n",
    "\n",
    "Constants:\n",
    "\n",
    "- γ = 8. \n",
    "- A portfolio starting value: 100.\n",
    "- Inflation-adjusted stock returns 1928-2015 (all numbers we use are inflation-adjusted, and we maximize inflation-adjusted cash flow).\n",
    "- Inflation-adjusted bond returns 1928-2015.\n",
    "\n",
    "Operations:\n",
    "\n",
    "- Calculate 59 30-vectors, each one representing the cash flow of one 30-year retirement cohort 1928-1986, using the given constant spending, variable spending, and stock allocation.\n",
    "- Calculate the certainty equivalent cash flow of each cohort using γ.\n",
    "- Calculate the certainty equivalent cash flow over all cohorts using γ.\n",
    "\n",
    "Use TensorFlow GradientDescentOptimizer to find the variables that resulted in the highest CE spending over all cohorts.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "from time import strftime\n",
    "import sys\n",
    "import six\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lifetable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# TensorFlow numeric type to use for floating point variables\n",
    "# tf.float32 is 2x faster but less accurate\n",
    "# tf.float64 will run out of accuracy for high gamma (> 8)\n",
    "float_type = tf.float64\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# returns 1928-2015\n",
    "############################################################\n",
    "\n",
    "first_year = 1928\n",
    "last_year = 2015\n",
    "years = range(first_year, last_year+1) # pythonically yields [1928, 1929...2015]\n",
    "years_history = len(years)\n",
    "years_retired = 30\n",
    "num_cohorts = years_history - years_retired + 1\n",
    "num_assets = 2\n",
    "\n",
    "bestfile = \"jupyter\"\n",
    "#gamma = 1.0\n",
    "\n",
    "sp500 = pd.Series([\n",
    "    0.4381,-0.083,-0.2512,-0.4384,-0.0864,0.4998,-0.0119,0.4674,0.3194,-0.3534,0.2928,-0.011,\n",
    "    -0.1067,-0.1277,0.1917,0.2506,0.1903,0.3582,-0.0843,0.052,0.057,0.183,0.3081,0.2368,0.1815,\n",
    "    -0.0121,0.5256,0.326,0.0744,-0.1046,0.4372,0.1206,0.0034,0.2664,-0.0881,0.2261,0.1642,0.124,\n",
    "    -0.0997,0.238,0.1081,-0.0824,0.0356,0.1422,0.1876,-0.1431,-0.259,0.37,0.2383,-0.0698,0.0651,\n",
    "    0.1852,0.3174,-0.047,0.2042,0.2234,0.0615,0.3124,0.1849,0.0581,0.1654,0.3148,-0.0306,0.3023,\n",
    "    0.0749,0.0997,0.0133,0.372,0.2268,0.331,0.2834,0.2089,-0.0903,-0.1185,-0.2197,0.2836,0.1074,\n",
    "    0.0483,0.1561,0.0548,-0.3655,0.2594,0.1482,0.021,0.1589,0.3215,0.1352,0.0136],\n",
    "    index = years)\n",
    "\n",
    "bonds=pd.Series([\n",
    "    0.0084,0.042,0.0454,-0.0256,0.0879,0.0186,0.0796,0.0447,0.0502,0.0138,0.0421,0.0441,\n",
    "    0.054,-0.0202,0.0229,0.0249,0.0258,0.038,0.0313,0.0092,0.0195,0.0466,0.0043,-0.003,\n",
    "    0.0227,0.0414,0.0329,-0.0134,-0.0226,0.068,-0.021,-0.0265,0.1164,0.0206,0.0569,0.0168,\n",
    "    0.0373,0.0072,0.0291,-0.0158,0.0327,-0.0501,0.1675,0.0979,0.0282,0.0366,0.0199,0.0361,\n",
    "    0.1598,0.0129,-0.0078,0.0067,-0.0299,0.082,0.3281,0.032,0.1373,0.2571,0.2428,-0.0496,\n",
    "    0.0822,0.1769,0.0624,0.15,0.0936,0.1421,-0.0804,0.2348,0.0143,0.0994,0.1492,-0.0825,\n",
    "    0.1666,0.0557,0.1512,0.0038,0.0449,0.0287,0.0196,0.1021,0.201,-0.1112,0.0846,0.1604,\n",
    "    0.0297,-0.091,0.1075,0.0128],\n",
    "                index=years)\n",
    "\n",
    "cpi=pd.Series([\n",
    "    -0.0115607,0.005848,-0.0639535,-0.0931677,-0.1027397,0.0076336,0.0151515,0.0298507,\n",
    "    0.0144928,0.0285714,-0.0277778,0,0.0071429,0.0992908,0.0903226,0.0295858,0.0229885,\n",
    "    0.0224719,0.1813187,0.0883721,0.0299145,-0.0207469,0.059322,0.06,0.0075472,0.0074906,\n",
    "    -0.0074349,0.0037453,0.0298507,0.0289855,0.0176056,0.017301,0.0136054,0.0067114,0.0133333,\n",
    "    0.0164474,0.0097087,0.0192308,0.0345912,0.0303951,0.0471976,0.0619718,0.0557029,0.0326633,\n",
    "    0.0340633,0.0870588,0.1233766,0.0693642,0.0486486,0.0670103,0.0901771,0.1329394,0.125163,\n",
    "    0.0892236,0.0382979,0.0379098,0.0394867,0.0379867,0.010979,0.0443439,0.0441941,0.046473,\n",
    "    0.0610626,0.0306428,0.0290065,0.0274841,0.026749,0.0253841,0.0332248,0.017024,0.016119,\n",
    "    0.0268456,0.0338681,0.0155172,0.0237691,0.0187949,0.0325556,0.0341566,0.0254065,0.0408127,\n",
    "    0.0009141,0.0272133,0.0149572,0.0296,0.0174,0.015,0.0076,0.0073],\n",
    "              index=years)\n",
    "\n",
    "real_stocks = sp500 - cpi\n",
    "real_bonds = bonds - cpi\n",
    "\n",
    "startval = 100\n",
    "years_retired = 30\n",
    "# 1% constant spending\n",
    "const_spend_pct = .0225\n",
    "const_spend = startval * const_spend_pct\n",
    "\n",
    "# var spending a function of years left\n",
    "var_spend_pcts = pd.Series([ 0.5/(30-ix) for ix in range(30)])\n",
    "var_spend_pcts[29] = 1.0\n",
    "\n",
    "# stocks starting at 82%, decreasing 0.5% per year\n",
    "stock_allocations = pd.Series([0.82 - 0.005* ix for ix in range(30)])\n",
    "bond_allocations = 1 - stock_allocations\n",
    "\n",
    "pickle_list = [const_spend, var_spend_pcts, stock_allocations, bond_allocations]\n",
    "pickle.dump( pickle_list, open( bestfile, \"wb\" ) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SafeWithdrawalModel:\n",
    "    \"\"\"initialize graph and parameters shared by all retirement cohorts\"\"\"\n",
    "    def __init__(self,\n",
    "                 returns_list, # series with returns for assets\n",
    "                 names_list, # names of assets\n",
    "                 allocations_list, # list of % allocated to each asset class\n",
    "                 start_val, # starting portfolio value e.g. 100\n",
    "                 const_spend,\n",
    "                 var_spend_pcts,\n",
    "                 gamma,\n",
    "                 survival,\n",
    "                 verbose=False):\n",
    "\n",
    "        # read params, initialize Tensorflow graph and session\n",
    "        # set up ops specific to model\n",
    "        self.verbose=verbose\n",
    "        self.startval=startval\n",
    "        self.returns_list = returns_list\n",
    "        self.names_list = names_list\n",
    "        self.num_assets = len(self.names_list)\n",
    "        self.start_val = start_val\n",
    "        self.ret_years = len(allocations_list[0])\n",
    "        self.const_spend = const_spend\n",
    "        self.var_spend_pcts = var_spend_pcts\n",
    "        self.survival=survival\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # model will have a cohort_history object, optimizer object\n",
    "        # initialize with placeholder, needs rest of model initialized first\n",
    "        self.cohort_history = None\n",
    "        self.optimizer = None\n",
    "\n",
    "        self.first_year = returns_list[0].index[0]\n",
    "        self.last_year = returns_list[0].index[-1]\n",
    "        self.total_cohorts = len(returns_list[0])\n",
    "        self.ret_cohorts = self.total_cohorts - self.ret_years + 1\n",
    "\n",
    "        print('%s Create TensorFlow graph and session' % strftime(\"%H:%M:%S\"))\n",
    "        self.graph = tf.Graph()\n",
    "        self.sess = tf.Session(graph = self.graph)\n",
    "        self.return_ops = []\n",
    "        self.allocation_ops = []\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                # some constants\n",
    "                self.zero = tf.constant(0.0, dtype=float_type, name=\"zero\")\n",
    "                self.one = tf.constant(1.0, dtype=float_type, name=\"one\")\n",
    "                self.one_hundred = tf.constant(100.0, dtype=float_type, name=\"one_hundred\")\n",
    "                self.ten_thousand = tf.constant(10000.0, dtype=float_type, name=\"ten_thousand\")\n",
    "                self.one_hundred_thousand = tf.constant(100000.0, dtype=float_type, name=\"one_million\")\n",
    "                self.one_million = tf.constant(1000000.0, dtype=float_type, name=\"one_million\")\n",
    "                self.very_small_amts = tf.constant(np.array([0.000001] * self.ret_years),\n",
    "                                                   dtype=float_type, name=\"very_small_amts\")\n",
    "                self.zero_years = tf.constant(np.zeros(self.ret_years),\n",
    "                                              dtype=float_type, name = \"zero_years\")\n",
    "                self.one_years = tf.constant(np.ones(self.ret_years), dtype=float_type, name=\"one_years\")\n",
    "                self.ret_years_op = tf.constant(self.ret_years, dtype=float_type, name=\"ret_years\")\n",
    "                #gamma\n",
    "                self.gamma_op = tf.constant(gamma, dtype=float_type, name=\"gamma\")\n",
    "                self.one_minus_gamma = tf.sub(self.one, self.gamma, name=\"one_minus_gamma\")\n",
    "                self.inv_one_minus_gamma = tf.div(self.one, self.one_minus_gamma,\n",
    "                                                  name=\"inv_one_minus_gamma\")\n",
    "\n",
    "                self.cost_multiplier = self.ten_thousand\n",
    "\n",
    "                # generate op for start_val\n",
    "                self.start_val_op = tf.constant(100.0, dtype=float_type, name =\"port_start_val\")\n",
    "\n",
    "                # generate ops for returns\n",
    "                for prefix, return_series in zip(names_list, returns_list):\n",
    "                    self.return_ops.append(self.gen_tf_const_list(return_series, \"%s_return\" % prefix,\n",
    "                                                                  verbose=self.verbose))\n",
    "\n",
    "                # only implemented for n=2 assets\n",
    "                # generate ops for allocations for first n-1 assets\n",
    "                prefix = names_list[0]\n",
    "                alloc_series = allocations_list[0]\n",
    "                stock_alloc_ops = self.gen_tf_var_list(alloc_series, \"%s_alloc\" % prefix,\n",
    "                                                       verbose=self.verbose)\n",
    "                self.allocation_ops.append(stock_alloc_ops)\n",
    "\n",
    "                # ops for soft constraints: 0 < stock allocation < 1\n",
    "                self.alloc_min_0_ops = self.gen_zero_min_list(stock_alloc_ops, \"alloc_min_0\",\n",
    "                                                              verbose=self.verbose)\n",
    "                self.cost_alloc_min_0_op = tf.mul(self.cost_multiplier,\n",
    "                                                  tf.add_n(self.alloc_min_0_ops,\n",
    "                                                           name=\"cost_alloc_min_0\"),\n",
    "                                                  name=\"cost_alloc_min_0_mult\")\n",
    "\n",
    "                self.alloc_max_1_ops = self.gen_one_max_list(stock_alloc_ops, \"alloc_max_1\",\n",
    "                                                             verbose=self.verbose)\n",
    "                self.cost_alloc_max_1_op = tf.mul(self.cost_multiplier,\n",
    "                                                  tf.add_n(self.alloc_max_1_ops, name = \"cost_alloc_max_1\"))\n",
    "\n",
    "                # ops for soft constraints: declining stock allocation\n",
    "                # why? for example, 1966 is the worst cohort, and 1974 is its worst stock return (-40%)\n",
    "                # to maximize CE, optimization sets stock allocation at a minimum to not run out of money\n",
    "                # in worst year. It will go e.g. 80% stock alloc in year 8 and 56% in year 9, return to\n",
    "                # 80% in year 10.To avoid artifacts like that, knowing stock allocation should decline\n",
    "                # over time, we add a large penalty to objective when stock allocation increases\n",
    "                # from one year to next.\n",
    "                self.alloc_decrease_ops = self.gen_diff_list(stock_alloc_ops, \"alloc_decrease\",\n",
    "                                                             verbose=self.verbose)\n",
    "                self.cost_alloc_decrease_op = tf.mul(self.cost_multiplier,\n",
    "                                                     tf.add_n(self.alloc_decrease_ops,\n",
    "                                                              name=\"alloc_decrease_cost_op\"))\n",
    "                # last asset is 1-previous assets\n",
    "                bond_alloc_ops = []\n",
    "\n",
    "                var_prefix = \"%s_alloc\" % names_list[1]\n",
    "                print ('%s Create ops for %s' % (strftime(\"%H:%M:%S\"), var_prefix))\n",
    "                for ix, op in enumerate(stock_alloc_ops):\n",
    "                    var_name = \"%s_%d\" % (var_prefix, ix)\n",
    "                    if self.verbose:\n",
    "                        print('Create %s' % var_name)\n",
    "                    var_op = tf.sub(self.one, stock_alloc_ops[ix], name=var_name)\n",
    "                    bond_alloc_ops.append(var_op)\n",
    "                self.allocation_ops.append(bond_alloc_ops)\n",
    "\n",
    "                # generate ops for const, var spending\n",
    "                self.const_spending_op = tf.Variable(const_spend, dtype=float_type, name=\"const_spend\")\n",
    "                self.sess.run(self.const_spending_op.initializer)\n",
    "\n",
    "                self.var_spending_ops = self.gen_tf_var_list(self.var_spend_pcts, \"var_spend\",\n",
    "                                                             verbose=self.verbose)\n",
    "\n",
    "                # all ops to be trained\n",
    "                self.all_var_ops = [self.const_spending_op] + \\\n",
    "                                   self.var_spending_ops + \\\n",
    "                                   self.allocation_ops[0]\n",
    "\n",
    "                # op for soft constraint: const spending > 0\n",
    "                self.cspend_min_0_op = tf.maximum(self.zero, tf.neg(self.const_spending_op,\n",
    "                                                                    name=\"neg_cspend_min_0_op\"),\n",
    "                                                  name=\"cspend_min_0_op\")\n",
    "                self.cost_cspend_min_0_op = tf.mul(self.cost_multiplier,\n",
    "                                                   self.cspend_min_0_op,\n",
    "                                                   name=\"cost_cspend_min_0\")\n",
    "\n",
    "                # op for soft constraint: var spending > 0\n",
    "                self.vspend_min_0_ops = self.gen_zero_min_list(self.var_spending_ops, \"vspend_min_0\",\n",
    "                                                               verbose=self.verbose)\n",
    "                self.cost_vspend_min_0_op = tf.mul(self.cost_multiplier,\n",
    "                                                   tf.add_n(self.vspend_min_0_ops,\n",
    "                                                            name=\"cost_vspend_min_0\"))\n",
    "\n",
    "                if survival is not None:\n",
    "                    survival_array=np.array(survival)\n",
    "                    self.survival_tensor = tf.constant(survival_array, dtype=float_type,\n",
    "                                                       name=\"survival_tensor\")\n",
    "\n",
    "                # global step counter\n",
    "                self.step_count = tf.Variable(0, dtype=float_type, name=\"step_count\", trainable=False)\n",
    "                self.increment_step = self.step_count.assign_add(1)\n",
    "\n",
    "                #init op\n",
    "                self.init_op = tf.initialize_all_variables()\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"When deleting model, close session, clear default graph\"\"\"\n",
    "        print(\"Destructor reset graph\")\n",
    "        try:\n",
    "            with self.graph.as_default():\n",
    "                tf.reset_default_graph()\n",
    "        except Exception, e:\n",
    "            print (\"Destructor couldn't reset graph: %s\" % str(e))\n",
    "\n",
    "        try:\n",
    "            print (\"Destructor close Tensorflow session\")\n",
    "            self.sess.close()\n",
    "        except Exception, e:\n",
    "            print (\"Destructor couldn't close session: %s\" % str(e))\n",
    "\n",
    "\n",
    "    def gen_tf_const_list(self, const_iter, const_prefix, start_index=0, verbose=False):\n",
    "        \"\"\"take a list or iterator of values, generate and return tensorflow constant ops for each\"\"\"\n",
    "        print ('%s Create constants %s' % (strftime(\"%H:%M:%S\"), const_prefix))\n",
    "        with self.graph.as_default():\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "\n",
    "                const_list = []\n",
    "                for ix, const in enumerate(const_iter):\n",
    "                    const_name = \"%s_%d\" % (const_prefix, start_index + ix)\n",
    "                    if verbose:\n",
    "                        print(\"Set constant %s to %f\" % (const_name, const))\n",
    "                    const_list.append(tf.constant(const, dtype=float_type, name=const_name))\n",
    "\n",
    "        return const_list\n",
    "\n",
    "    def gen_tf_var_list(self, var_iter, var_prefix, start_index=0, verbose=False):\n",
    "        \"\"\"take a list or iterator of values, generate and return tensorflow Variable ops for each\"\"\"\n",
    "        print ('%s Create variables %s' % (strftime(\"%H:%M:%S\"), var_prefix))\n",
    "        with self.graph.as_default():\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                var_list = []\n",
    "                for ix, var in enumerate(var_iter):\n",
    "                    var_name = \"%s_%d\" % (var_prefix, start_index + ix)\n",
    "                    if verbose:\n",
    "                        print(\"Create variable %s to %f\" % (var_name, var))\n",
    "                    var_op = tf.Variable(var, dtype=float_type, name=var_name)\n",
    "                    self.sess.run(var_op.initializer)\n",
    "                    var_list.append(var_op)\n",
    "\n",
    "        return var_list\n",
    "\n",
    "    def get_op_from_list(self, op_list, op_index):\n",
    "        \"\"\"take a list of ops, return value of op specified by op_index\"\"\"\n",
    "        op = op_list[op_index]\n",
    "        retval = self.sess.run([op])\n",
    "        return retval\n",
    "\n",
    "    def gen_zero_min_list(self, op_iter, op_prefix, start_index=0, verbose=False):\n",
    "        \"\"\"take a list or iterator of ops, generate and return an op which is max(-op, 0)\n",
    "        for soft constraints > 0\"\"\"\n",
    "        print ('%s Create ops for soft constraint %s > 0' % (strftime(\"%H:%M:%S\"), op_prefix))\n",
    "        with self.graph.as_default():\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                op_list = []\n",
    "                for ix, op in enumerate(op_iter):\n",
    "                    op_name = \"%s_%d\" % (op_prefix, start_index + ix)\n",
    "                    if verbose:\n",
    "                        print(\"Zero_min op %s\" % op_name)\n",
    "                    new_op = tf.maximum(self.zero, tf.neg(op, name=\"neg_%s\" % op_name), name=op_name)\n",
    "                    op_list.append(new_op)\n",
    "\n",
    "        return op_list\n",
    "\n",
    "    def gen_one_max_list(self, op_iter, op_prefix, start_index=0, verbose=False):\n",
    "        \"\"\"take a list or iterator of ops, generate and return an op with is max(op-1, 0)\n",
    "        for soft constraints > 0\"\"\"\n",
    "        print ('%s Create ops for soft constraint %s < 1' % (strftime(\"%H:%M:%S\"), op_prefix))\n",
    "        with self.graph.as_default():\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                op_list = []\n",
    "                for ix, op in enumerate(op_iter):\n",
    "                    op_name = \"%s_%d\" % (op_prefix, start_index + ix)\n",
    "                    if verbose:\n",
    "                        print('One_max op %s' % op_name)\n",
    "                    new_op = tf.maximum(self.zero, tf.sub(op, self.one, name=\"one_minus_%s\" % op_name),\n",
    "                        name=op_name)\n",
    "                    op_list.append(new_op)\n",
    "\n",
    "        return op_list\n",
    "\n",
    "    def gen_diff_list(self, op_iter, op_prefix, start_index=0, verbose=False):\n",
    "        \"\"\"generate and return an op for declining stock alloc constraint over time, max of 0 and decrease\"\"\"\n",
    "        print ('%s Create ops for soft constraint, declining stock alloc %s' % (strftime(\"%H:%M:%S\"),\n",
    "                                                                                op_prefix))\n",
    "        with self.graph.as_default():\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                op_list = []\n",
    "                for ix, op in enumerate(op_iter):\n",
    "                    if ix == 0:\n",
    "                        continue\n",
    "                    op_name = \"%s_%d\" % (op_prefix, start_index + ix)\n",
    "                    if verbose:\n",
    "                        print(\"diff op %s\" % op_name)\n",
    "\n",
    "                    new_op = tf.maximum(self.zero, tf.sub(op_iter[ix], op_iter[ix-1]))\n",
    "                    op_list.append(new_op)\n",
    "\n",
    "        return op_list\n",
    "\n",
    "    def gen_ce(self, input_tensor, prefix, survival_tensor=None):\n",
    "      with tf.device(\"/cpu:0\"):\n",
    "        with self.graph.as_default():\n",
    "            input_length = np.float64(input_tensor.get_shape().as_list()[0])\n",
    "\n",
    "            print(\"%s Create ce op with gamma: %f\" % (strftime(\"%H:%M:%S\"), self.gamma))\n",
    "            if self.gamma == 1.0:\n",
    "                u = tf.reduce_mean(tf.log(input_tensor), name=\"%s_u\" % prefix)\n",
    "                #print(self.sess.run(u))\n",
    "                if survival_tensor is not None:\n",
    "                    u0 = u\n",
    "                    u = tf.reduce_mean(tf.mul(u0, survival_tensor, name=\"%s_u_surv\" % prefix),\n",
    "                                       name=\"%s_u\" % prefix)\n",
    "                ce = tf.mul(tf.exp(u), input_length, name=\"%s_ce\" % prefix)\n",
    "                print ('%s Create CE op %f' % (strftime(\"%H:%M:%S\"), self.sess.run(ce)))\n",
    "            else:\n",
    "                # for high gamma numerical error is significant, calculation is most accurate near 1\n",
    "                # so divide by mean\n",
    "                input_mean = tf.reduce_mean(input_tensor, name=\"%s_mean\" % prefix)\n",
    "                input_conditioned = tf.div(input_tensor, input_mean, name=\"%s_conditioned\" % prefix)\n",
    "\n",
    "                u1 = tf.pow(input_conditioned, self.one_minus_gamma, name=\"%s_u1\" % prefix)\n",
    "                u2 = tf.sub(u1, self.one, name=\"%s_u2\" % prefix)\n",
    "                u3 = tf.mul(u2, self.inv_one_minus_gamma, name=\"%s_u3\" % prefix)\n",
    "                u = tf.reduce_mean(u3, name=\"%s_u\" % prefix)\n",
    "\n",
    "                if survival_tensor is not None:\n",
    "                    u4 = u\n",
    "                    u = tf.reduce_mean(tf.mul(u4, survival_tensor, name=\"%s_u_surv\" % prefix),\n",
    "                        name=\"%s_u\" % prefix)\n",
    "\n",
    "                ce1 = tf.mul(self.one_minus_gamma, u, name=\"%s_ce1\" % prefix)\n",
    "                ce2 = tf.add(ce1, self.one, name=\"%s_ce2\" % prefix)\n",
    "                ce3 = tf.pow(ce2, self.inv_one_minus_gamma, name=\"%s_ce3\" % prefix)\n",
    "                ce = tf.mul(input_mean, ce3, name=\"%s_ce\" % prefix)\n",
    "\n",
    "                print ('%s Create CE op %f' % (strftime(\"%H:%M:%S\"), self.sess.run(ce)))\n",
    "            return ce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cohort:\n",
    "    \"\"\"Cohort represents experience of an individual\n",
    "       - retiring in a given year\n",
    "       - using the specified SafeWithdrawal model\"\"\"\n",
    "    def __init__(self, model, cohort_start_year):\n",
    "        self.model = model\n",
    "        self.cohort_start_year = cohort_start_year\n",
    "        self.name = \"cohort_%d\" % cohort_start_year\n",
    "        print(\"%s Instantiating cohort %s\" % (strftime(\"%H:%M:%S\"), self.name))\n",
    "        self.gen_tf_ops()\n",
    "\n",
    "    def gen_tf_ops(self):\n",
    "\n",
    "        stock_returns = self.model.return_ops[0]\n",
    "        bond_returns = self.model.return_ops[1]\n",
    "\n",
    "        stock_allocs = self.model.allocation_ops[0]\n",
    "        bond_allocs = self.model.allocation_ops[1]\n",
    "\n",
    "        self.port_returns_list = []\n",
    "        self.port_prespend_list = []\n",
    "        self.port_end_vals_list = []\n",
    "        self.spend_amts_list = []\n",
    "        self.spend_amts_nonzero_list = []\n",
    "\n",
    "        with self.model.graph.as_default():\n",
    "          with tf.device(\"/cpu:0\"):\n",
    "\n",
    "            print (\"%s Generating %d years from %d\" % (strftime(\"%H:%M:%S\"),\n",
    "                                                       self.model.ret_years,\n",
    "                                                       self.cohort_start_year))\n",
    "\n",
    "            start_year_ix = self.cohort_start_year - self.model.first_year\n",
    "            for ix in range(self.model.ret_years):\n",
    "                op_stock_return = stock_returns[start_year_ix + ix]\n",
    "                op_stock_alloc = stock_allocs[ix]\n",
    "                op_bond_return = bond_returns[start_year_ix + ix]\n",
    "                op_bond_alloc = bond_allocs[ix]\n",
    "\n",
    "                op_const_spend = self.model.const_spending_op\n",
    "                op_var_spend = self.model.var_spending_ops[ix]\n",
    "\n",
    "                op_total_real_return = tf.add(tf.mul(op_stock_alloc, op_stock_return, name=\"%s_stock_%d\"\n",
    "                                                     % (self.name, ix)),\n",
    "                                              tf.mul(op_bond_alloc, op_bond_return, name=\"%s_bond_%d\"\n",
    "                                                     % (self.name, ix)),\n",
    "                                              name=\"%s_total_return_%d\" % (self.name, ix))\n",
    "                self.port_returns_list.append(op_total_real_return)\n",
    "\n",
    "                if ix == 0:\n",
    "                    prev_val = self.model.start_val_op\n",
    "                else:\n",
    "                    prev_val = self.port_end_vals_list[ix-1]\n",
    "\n",
    "                op_port_end_val_prespend = tf.add(prev_val,\n",
    "                                                  tf.mul(prev_val, self.port_returns_list[ix],\n",
    "                                                         name=\"%s_dolreturn_%d\" % (self.name, ix)),\n",
    "                                                  name=\"%s_prespend_%d\" % (self.name, ix))\n",
    "                self.port_prespend_list.append(op_port_end_val_prespend)\n",
    "\n",
    "                desired_spend_amt = tf.add(tf.mul(op_var_spend, op_port_end_val_prespend,\n",
    "                    name=\"%s_des_vspend_%d\" % (self.name, ix)),\n",
    "                                           op_const_spend,\n",
    "                                           name=\"%s_desired_spend_amt_%d\" % (self.name, ix))\n",
    "                #spend minimum of tmp_spend_amt, port value\n",
    "                spend_amt = tf.minimum(desired_spend_amt, op_port_end_val_prespend,\n",
    "                                       name=\"%s_actual_spend_amt_%d\" % (self.name, ix))\n",
    "                self.spend_amts_list.append(spend_amt)\n",
    "\n",
    "                op_port_end_val = tf.sub(op_port_end_val_prespend, spend_amt, name=\"%s_endval_%d\" %\n",
    "                                                                                   (self.name, ix))\n",
    "                self.port_end_vals_list.append(op_port_end_val)\n",
    "\n",
    "            #now that we've computed cohort paths we pack results into 1D Tensors to calc objective\n",
    "            self.spend_amts = tf.pack(self.spend_amts_list, name=\"%s_spend_amts\" % self.name)\n",
    "            self.port_end_vals = tf.pack(self.port_end_vals_list, name=\"%s_port_end_vals\" % self.name)\n",
    "\n",
    "            self.mean_spending = tf.reduce_mean(self.spend_amts, name=\"%s_mean_spending\" % self.name)\n",
    "            self.sd_spending = tf.sqrt(tf.reduce_mean(tf.pow(tf.sub(self.spend_amts,\n",
    "                                                                    self.mean_spending), 2)),\n",
    "                                       name=\"%s_sd_spending\" % self.name)\n",
    "            self.min_spending = tf.reduce_min(self.spend_amts, name=\"%s_min_spending\" % self.name)\n",
    "            self.max_spending = tf.reduce_max(self.spend_amts, name=\"%s_max_spending\" % self.name)\n",
    "\n",
    "            if self.model.gamma == 1.0:\n",
    "                #spend a tiny amount even if spend is 0 so log is not NaN\n",
    "                #doesn't really seem like best practice but...\n",
    "                #0 spend years can't be in final solution\n",
    "                #and don't want divide by zero errors if optimizer attempts one\n",
    "\n",
    "                #chain new op off old op but keep a reference to old op around just in case\n",
    "                self.spend_amts_maybe_zero = self.spend_amts\n",
    "                self.spend_amts = tf.maximum(self.spend_amts_maybe_zero,\n",
    "                                             self.model.very_small_amts,\n",
    "                                             name=\"%s_actual_spend_nonzero\" % self.name)\n",
    "                self.total_spending = tf.reduce_sum(self.spend_amts, name=\"%s_total_spending_nonzero\" %\n",
    "                                                    self.name)\n",
    "            else:\n",
    "                self.total_spending = tf.reduce_sum(self.spend_amts, name=\"%s_total_spending\" %\n",
    "                                                    self.name)\n",
    "\n",
    "            if self.model.survival is not None:\n",
    "                self.ce = self.model.gen_ce_survival(self.spend_amts,\n",
    "                                                     self.model.survival_tensor,\n",
    "                                                     \"%s_ce\" % self.name)\n",
    "            else:\n",
    "                self.ce = self.model.gen_ce(self.spend_amts,\n",
    "                                            \"%s_ce\" % self.name)\n",
    "\n",
    "            #print (self.as_dataframe())\n",
    "\n",
    "    def get_tf_ops(self):\n",
    "        return self.model.start_val, self.port_returns_list, self.port_prespend_list, \\\n",
    "            self.spend_amts_list, self.port_end_vals_list, self.total_spending\n",
    "\n",
    "    def as_dataframe(self):\n",
    "        port_returns_ops = self.port_returns_list\n",
    "        port_prespend_ops = self.port_prespend_list\n",
    "        spend_amts_ops = self.spend_amts_list\n",
    "        port_end_vals_ops = self.port_end_vals_list\n",
    "\n",
    "        port_returns = self.model.sess.run(port_returns_ops)\n",
    "        port_prespend = self.model.sess.run(port_prespend_ops)\n",
    "        spend_amts = self.model.sess.run(spend_amts_ops)\n",
    "        port_end_vals = self.model.sess.run(port_end_vals_ops)\n",
    "\n",
    "        retlist = []\n",
    "        for ix in range(self.model.ret_years):\n",
    "            retlist.append([port_returns[ix],\n",
    "                            port_prespend[ix],\n",
    "                            spend_amts[ix],\n",
    "                            port_end_vals[ix]\n",
    "                        ])\n",
    "\n",
    "        years = range(self.cohort_start_year, self.cohort_start_year+self.model.ret_years)\n",
    "        return pd.DataFrame(retlist,\n",
    "                            index = years,\n",
    "                            columns=['portreturn', 'prespend', 'spend_amt', 'end_val'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CohortHistory:\n",
    "    \"\"\"represents a set of cohorts retiring in different years using a strategy,\n",
    "    to enabling aggregating and summarizing their experiences\"\"\"\n",
    "    def __init__(self, model, cohort_years = None):\n",
    "        self.model = model\n",
    "        if cohort_years is None:\n",
    "            cohort_years = [year for year in range(self.model.first_year,\n",
    "                                                   self.model.first_year + self.model.ret_cohorts)]\n",
    "\n",
    "        print('%s Create cohort history, years %d to %d' % (strftime(\"%H:%M:%S\"),\n",
    "                                                            cohort_years[0], cohort_years[-1]))\n",
    "        self.cohort_list = [Cohort(model, year) for year in cohort_years]\n",
    "        self.total_spending_ops = [cohort.total_spending for cohort in self.cohort_list]\n",
    "\n",
    "    def as_dataframe(self):\n",
    "        \"\"\"report on on each cohort by year, e.g. 1928\"\"\"\n",
    "        total_spending_ops = [cohort.total_spending for cohort in self.model.cohort_history.cohort_list]\n",
    "        mean_spending_ops = [cohort.mean_spending for cohort in self.model.cohort_history.cohort_list]\n",
    "        sd_spending_ops = [cohort.sd_spending for cohort in self.model.cohort_history.cohort_list]\n",
    "        min_spending_ops = [cohort.min_spending for cohort in self.model.cohort_history.cohort_list]\n",
    "        max_spending_ops = [cohort.max_spending for cohort in self.model.cohort_history.cohort_list]\n",
    "        ce_ops = [cohort.ce for cohort in self.model.cohort_history.cohort_list]\n",
    "\n",
    "        retlist = []\n",
    "        years = range(self.model.first_year, self.model.first_year + self.model.ret_cohorts)\n",
    "        for year, \\\n",
    "            meanspend, \\\n",
    "            sdspend, \\\n",
    "            minspend, \\\n",
    "            maxspend, \\\n",
    "            totalspend, \\\n",
    "            ce in zip(years, self.model.sess.run(mean_spending_ops),\n",
    "                      self.model.sess.run(sd_spending_ops),\n",
    "                      self.model.sess.run(min_spending_ops),\n",
    "                      self.model.sess.run(max_spending_ops),\n",
    "                      self.model.sess.run(total_spending_ops),\n",
    "                      self.model.sess.run(ce_ops)):\n",
    "\n",
    "            retlist.append([meanspend, sdspend, minspend, maxspend, totalspend, ce])\n",
    "\n",
    "        return pd.DataFrame(retlist, index = years,\n",
    "                            columns=['mean_spend', 'sd_spend', 'min_spend', 'max_spend', 'total_spend', 'ce'])\n",
    "\n",
    "    def spend_by_year(self):\n",
    "        \"\"\"report spending by year for each cohort (ret_years rows x num_cohorts)\"\"\"\n",
    "        dataframes = [cohort.as_dataframe() for cohort in self.model.cohort_history.cohort_list]\n",
    "        years = range(self.model.ret_years)\n",
    "        cohorts = range(len(dataframes))\n",
    "\n",
    "        retlist = []\n",
    "        for ix in years:\n",
    "            spendlist = [df.spend_amt.iloc[ix] for df in dataframes]\n",
    "            retlist.append(spendlist)\n",
    "\n",
    "        colnames = [\"%d\" % (cohort+self.model.first_year) for cohort in cohorts]\n",
    "        return pd.DataFrame(retlist, index = years, columns=colnames)\n",
    "\n",
    "    def returns_by_year(self):\n",
    "        \"\"\"report returns by year for each cohort (ret_years rows x num_cohorts)\"\"\"\n",
    "        dataframes = [cohort.as_dataframe() for cohort in self.model.cohort_history.cohort_list]\n",
    "        years = range(self.model.ret_years)\n",
    "        cohorts = range(len(dataframes))\n",
    "\n",
    "        retlist = []\n",
    "        for ix in years:\n",
    "            returnlist = [df.portreturn.iloc[ix] for df in dataframes]\n",
    "            retlist.append(returnlist)\n",
    "\n",
    "        colnames = [\"%d\" % (cohort+self.model.first_year) for cohort in cohorts]\n",
    "        return pd.DataFrame(retlist, index = years, columns=colnames)\n",
    "\n",
    "    def summarize_by_year(self):\n",
    "        \"\"\"report on outcomes by retirement year, e.g. retirement year 1, 2...30\"\"\"\n",
    "        dataframes = [cohort.as_dataframe() for cohort in self.model.cohort_history.cohort_list]\n",
    "        years = range(self.model.ret_years)\n",
    "        retlist = []\n",
    "        for ix in years:\n",
    "            spendlist = np.array([df.spend_amt.iloc[ix] for df in dataframes])\n",
    "            spend_mean = np.mean(spendlist)\n",
    "            spend_sd = np.std(spendlist)\n",
    "            spend_min = np.min(spendlist)\n",
    "            spend_max = np.max(spendlist)\n",
    "            retlist.append([spend_mean, spend_sd, spend_min, spend_max])\n",
    "\n",
    "        return pd.DataFrame(retlist, index = years,\n",
    "                            columns=['spend_mean', 'spend_sd', 'spend_min', 'spend_max'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "# Create an op which is the sum of spending in all years\n",
    "#  - negate it so it will be minimized\n",
    "#  - add large penalty when a stock allocation is < 0 as a soft constraint\n",
    "#  - add large penalty when a stock allocation is > 1 as a soft constraint\n",
    "#  - add large penalty when const or var spencint is < 0 as a soft constraint\n",
    "#  - result is an op which can be minimized by gradient descent\n",
    "\n",
    "class CohortHistoryOptimize():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.best_objective = 0.0\n",
    "        self.best_step = 0\n",
    "\n",
    "        graph = self.model.graph\n",
    "\n",
    "        with graph.as_default():\n",
    "          with tf.device(\"/cpu:0\"):\n",
    "\n",
    "            print ('%s Create optimizer class' % strftime(\"%H:%M:%S\"))\n",
    "            print ('%s Run variable initializers' % strftime(\"%H:%M:%S\"))\n",
    "            self.model.sess.run(model.init_op)\n",
    "\n",
    "            print('%s Create cost ops' % strftime(\"%H:%M:%S\"))\n",
    "            print('%s Sum %d ce ops' % (strftime(\"%H:%M:%S\"), len(self.model.cohort_history.cohort_list)))\n",
    "            ce_ops = [cohort.ce for cohort in self.model.cohort_history.cohort_list]\n",
    "            ce_tensor = tf.pack(ce_ops, name=\"all_cohorts_ce_tensor\")\n",
    "\n",
    "            # ce over ret_cohorts years\n",
    "            self.total_ce_op = self.model.gen_ce(ce_tensor, \"all_cohorts_ce\")\n",
    "\n",
    "            print(\"%s Total CE spend, all cohorts: %f\" % (strftime(\"%H:%M:%S\"),\n",
    "                                                          self.model.sess.run(self.total_ce_op)))\n",
    "            # basic cost\n",
    "            cost_op_1 = tf.neg(self.total_ce_op, name=\"basic_cost\")\n",
    "            print(\"%s Raw cost objective: %f\" % (strftime(\"%H:%M:%S\"), self.model.sess.run(cost_op_1)))\n",
    "\n",
    "            cost_op_2 = tf.add(cost_op_1, model.cost_alloc_min_0_op, name=\"cost_add_alloc_min_0\")\n",
    "            print(\"%s Add soft constraint penalty if stock alloc < 0: %f\" %\n",
    "                  (strftime(\"%H:%M:%S\"), self.model.sess.run(cost_op_2)))\n",
    "\n",
    "            cost_op_3 = tf.add(cost_op_2, model.cost_alloc_max_1_op, name=\"cost_add_alloc_max_1\")\n",
    "            print(\"%s Add soft constraint penalty if stock alloc > 1: %f\" % (strftime(\"%H:%M:%S\"),\n",
    "                                                                             self.model.sess.run(cost_op_3)))\n",
    "\n",
    "            cost_op_4 = tf.add(cost_op_3, model.cost_vspend_min_0_op, name=\"cost_vspend_min_0\")\n",
    "            print(\"%s Add soft constraint penalty if var spending < 0: %f\" % (strftime(\"%H:%M:%S\"),\n",
    "                                                                              self.model.sess.run(cost_op_4)))\n",
    "\n",
    "            cost_op_5 = tf.add(cost_op_4, model.cost_cspend_min_0_op, name=\"cost_cspend_min_0\")\n",
    "            print(\"%s Add soft constraint if const spending < 0: %f\" % (strftime(\"%H:%M:%S\"),\n",
    "                                                                        self.model.sess.run(cost_op_5)))\n",
    "\n",
    "            self.cost_op = tf.add(cost_op_5, model.cost_alloc_decrease_op, name=\"cost_alloc_decrease\")\n",
    "            print(\"%s Add soft constraint if stock alloc increases in any year: %f\" %\n",
    "                  (strftime(\"%H:%M:%S\"), self.model.sess.run(self.cost_op)))\n",
    "\n",
    "            self.best_objective = -self.model.sess.run(self.cost_op)\n",
    "            print(\"%s All inclusive objective to be minimized: %f\" % (strftime(\"%H:%M:%S\"),\n",
    "                                                                      -self.best_objective))\n",
    "            self.best_const_spend = self.model.sess.run(model.const_spending_op)\n",
    "            self.best_var_spend = self.model.sess.run(model.var_spending_ops)\n",
    "            self.best_stock_alloc = self.model.sess.run(model.allocation_ops[0])\n",
    "\n",
    "    def run_step(self, report_steps=1):\n",
    "        \"\"\"run one step of optimizer\n",
    "           calc gradients\n",
    "           apply gradients * learning rate to each variable to descend gradient and improve objective\n",
    "           increment global step to remember how many steps we've run\n",
    "           if (hopefully) new objective is best to date, save params and objective\"\"\"\n",
    "\n",
    "        _, step = self.model.sess.run([self.optimize_step,\n",
    "                                       self.model.increment_step])\n",
    "        self.steps_ago +=1\n",
    "        cost = self.model.sess.run(self.cost_op)\n",
    "        assert not(np.isnan(cost)), \"Objective is nan\"\n",
    "        objective = - cost\n",
    "\n",
    "        #print objective each step\n",
    "        #print(\"objective %f best %f\" %(objective, self.best_objective))\n",
    "        if np.isnan(cost):\n",
    "            sys.stdout.write('X')\n",
    "            sys.stdout.flush()\n",
    "        elif objective > self.best_objective:\n",
    "            self.best_objective = objective\n",
    "            self.best_const_spend = self.model.sess.run(model.const_spending_op)\n",
    "            self.best_var_spend = self.model.sess.run(model.var_spending_ops)\n",
    "            self.best_stock_alloc = self.model.sess.run(model.allocation_ops[0])\n",
    "            self.best_step = step\n",
    "            self.steps_ago = 0\n",
    "            sys.stdout.write('!')\n",
    "            sys.stdout.flush()\n",
    "        else:\n",
    "            sys.stdout.write('.')\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        if step % report_steps == 0:\n",
    "            sys.stdout.write(\"\\n%s step %d objective %f best %f (%d steps ago)\\n\" %\n",
    "                             (strftime(\"%H:%M:%S\"),\n",
    "                              step,\n",
    "                              objective,\n",
    "                              self.best_objective,\n",
    "                              self.steps_ago))\n",
    "            # print variables optimized and gradients for debugging\n",
    "            # sys.stdout.write(\"\\n\")\n",
    "            # var_vals = self.model.sess.run(self.model.all_var_ops)\n",
    "            # print(\"%s Variables\" % strftime(\"%H:%M:%S\"))\n",
    "            # print(var_vals)\n",
    "\n",
    "            # grad_vals = self.model.sess.run([grad[0] for grad in self.grads])\n",
    "            # print(\"%s Gradients\" % strftime(\"%H:%M:%S\"))\n",
    "            # print(grad_vals)\n",
    "\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            self.best_bond_alloc = pd.Series([1 - bsa for bsa in self.best_stock_alloc])\n",
    "            pickle_list = [self.best_const_spend, self.best_var_spend, self.best_stock_alloc,\n",
    "                           self.best_bond_alloc]\n",
    "            pickle.dump( pickle_list, open( picklefile, \"wb\" ) )\n",
    "\n",
    "            # every 10 report_steps show current best\n",
    "            if step % (report_steps * 10) == 0:\n",
    "                print (\"\\n#Objective: %f\\n\" % self.best_objective)\n",
    "                print (\"const_spend = %f\" % self.best_const_spend)\n",
    "                print (\"var_spend_pcts = pd.Series(%s)\" % str(self.best_var_spend))\n",
    "                print (\"stock_allocations = pd.Series(%s)\\n\" %str(self.best_stock_alloc))\n",
    "\n",
    "    def optimize(self, learning_rate, steps):\n",
    "        \"\"\"create the op for the optimizer using specified learning_rate, run for specified steps\"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.steps = steps\n",
    "        self.steps_ago = 0 # how many steps since objective improved\n",
    "\n",
    "        print(\"%s Objective: %f\" % (strftime(\"%H:%M:%S\"), self.best_objective))\n",
    "        print(\"%s Constant spending: %f\" % (strftime(\"%H:%M:%S\"), self.best_const_spend))\n",
    "        print(\"%s Variable spending by year\" % strftime(\"%H:%M:%S\"))\n",
    "        print(self.best_var_spend)\n",
    "        print(\"%s Stock allocation by year\" % strftime(\"%H:%M:%S\"))\n",
    "        print(self.best_stock_alloc)\n",
    "\n",
    "        with self.model.graph.as_default():\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "\n",
    "                # minimize op\n",
    "                print('%s Create optimizer (learning rate %.12f)' % (strftime(\"%H:%M:%S\"),\n",
    "                                                                     self.learning_rate))\n",
    "                self.optimizer = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "                self.grads = self.optimizer.compute_gradients(self.cost_op)\n",
    "                self.optimize_step = self.optimizer.apply_gradients(self.grads)\n",
    "                # following line is equivalent to previous 2 lines\n",
    "                # self.optimize_step = self.optimizer.minimize(self.cost_op)\n",
    "\n",
    "        print('%s Create optimizer op and run %d steps' % (strftime(\"%H:%M:%S\"), self.steps))\n",
    "        for i in range(self.steps):\n",
    "            self.run_step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:59:50 Start optimization session\n",
      "16:59:50 learning_rate: 0.000000100000 steps 500 picklefile gamma_8.pickle\n",
      "const spend: 2.250000\n",
      "variable spend:\n",
      "0     0.016667\n",
      "1     0.017241\n",
      "2     0.017857\n",
      "3     0.018519\n",
      "4     0.019231\n",
      "5     0.020000\n",
      "6     0.020833\n",
      "7     0.021739\n",
      "8     0.022727\n",
      "9     0.023810\n",
      "10    0.025000\n",
      "11    0.026316\n",
      "12    0.027778\n",
      "13    0.029412\n",
      "14    0.031250\n",
      "15    0.033333\n",
      "16    0.035714\n",
      "17    0.038462\n",
      "18    0.041667\n",
      "19    0.045455\n",
      "20    0.050000\n",
      "21    0.055556\n",
      "22    0.062500\n",
      "23    0.071429\n",
      "24    0.083333\n",
      "25    0.100000\n",
      "26    0.125000\n",
      "27    0.166667\n",
      "28    0.250000\n",
      "29    1.000000\n",
      "dtype: float64\n",
      "stock allocation:\n",
      "0     0.820\n",
      "1     0.815\n",
      "2     0.810\n",
      "3     0.805\n",
      "4     0.800\n",
      "5     0.795\n",
      "6     0.790\n",
      "7     0.785\n",
      "8     0.780\n",
      "9     0.775\n",
      "10    0.770\n",
      "11    0.765\n",
      "12    0.760\n",
      "13    0.755\n",
      "14    0.750\n",
      "15    0.745\n",
      "16    0.740\n",
      "17    0.735\n",
      "18    0.730\n",
      "19    0.725\n",
      "20    0.720\n",
      "21    0.715\n",
      "22    0.710\n",
      "23    0.705\n",
      "24    0.700\n",
      "25    0.695\n",
      "26    0.690\n",
      "27    0.685\n",
      "28    0.680\n",
      "29    0.675\n",
      "dtype: float64\n",
      "16:59:50 Create TensorFlow graph and session\n",
      "16:59:50 Create constants stocks_return\n",
      "16:59:50 Create constants bonds_return\n",
      "16:59:50 Create variables stocks_alloc\n",
      "16:59:50 Create ops for soft constraint alloc_min_0 > 0\n",
      "16:59:50 Create ops for soft constraint alloc_max_1 < 1\n",
      "16:59:50 Create ops for soft constraint, declining stock alloc alloc_decrease\n",
      "16:59:50 Create ops for bonds_alloc\n",
      "16:59:50 Create variables var_spend\n",
      "16:59:51 Create ops for soft constraint vspend_min_0 > 0\n",
      "16:59:51 Create cohort history, years 1928 to 1986\n",
      "16:59:51 Instantiating cohort cohort_1928\n",
      "16:59:51 Generating 30 years from 1928\n",
      "16:59:51 Create ce op with gamma: 8.000000\n",
      "16:59:51 Create CE op 4.643645\n",
      "16:59:51 Instantiating cohort cohort_1929\n",
      "16:59:51 Generating 30 years from 1929\n",
      "16:59:51 Create ce op with gamma: 8.000000\n",
      "16:59:51 Create CE op 3.927663\n",
      "16:59:51 Instantiating cohort cohort_1930\n",
      "16:59:51 Generating 30 years from 1930\n",
      "16:59:52 Create ce op with gamma: 8.000000\n",
      "16:59:52 Create CE op 4.117642\n",
      "16:59:52 Instantiating cohort cohort_1931\n",
      "16:59:52 Generating 30 years from 1931\n",
      "16:59:52 Create ce op with gamma: 8.000000\n",
      "16:59:52 Create CE op 4.503485\n",
      "16:59:52 Instantiating cohort cohort_1932\n",
      "16:59:52 Generating 30 years from 1932\n",
      "16:59:52 Create ce op with gamma: 8.000000\n",
      "16:59:52 Create CE op 5.587242\n",
      "16:59:52 Instantiating cohort cohort_1933\n",
      "16:59:52 Generating 30 years from 1933\n",
      "16:59:52 Create ce op with gamma: 8.000000\n",
      "16:59:52 Create CE op 5.790120\n",
      "16:59:53 Instantiating cohort cohort_1934\n",
      "16:59:53 Generating 30 years from 1934\n",
      "16:59:53 Create ce op with gamma: 8.000000\n",
      "16:59:53 Create CE op 4.851973\n",
      "16:59:53 Instantiating cohort cohort_1935\n",
      "16:59:53 Generating 30 years from 1935\n",
      "16:59:53 Create ce op with gamma: 8.000000\n",
      "16:59:53 Create CE op 5.020730\n",
      "16:59:53 Instantiating cohort cohort_1936\n",
      "16:59:53 Generating 30 years from 1936\n",
      "16:59:53 Create ce op with gamma: 8.000000\n",
      "16:59:53 Create CE op 4.284851\n",
      "16:59:54 Instantiating cohort cohort_1937\n",
      "16:59:54 Generating 30 years from 1937\n",
      "16:59:54 Create ce op with gamma: 8.000000\n",
      "16:59:54 Create CE op 3.845672\n",
      "16:59:54 Instantiating cohort cohort_1938\n",
      "16:59:54 Generating 30 years from 1938\n",
      "16:59:54 Create ce op with gamma: 8.000000\n",
      "16:59:54 Create CE op 4.761143\n",
      "16:59:54 Instantiating cohort cohort_1939\n",
      "16:59:54 Generating 30 years from 1939\n",
      "16:59:54 Create ce op with gamma: 8.000000\n",
      "16:59:54 Create CE op 4.256801\n",
      "16:59:55 Instantiating cohort cohort_1940\n",
      "16:59:55 Generating 30 years from 1940\n",
      "16:59:55 Create ce op with gamma: 8.000000\n",
      "16:59:55 Create CE op 4.314835\n",
      "16:59:55 Instantiating cohort cohort_1941\n",
      "16:59:55 Generating 30 years from 1941\n",
      "16:59:55 Create ce op with gamma: 8.000000\n",
      "16:59:55 Create CE op 4.581398\n",
      "16:59:55 Instantiating cohort cohort_1942\n",
      "16:59:55 Generating 30 years from 1942\n",
      "16:59:55 Create ce op with gamma: 8.000000\n",
      "16:59:55 Create CE op 5.360601\n",
      "16:59:56 Instantiating cohort cohort_1943\n",
      "16:59:56 Generating 30 years from 1943\n",
      "16:59:56 Create ce op with gamma: 8.000000\n",
      "16:59:56 Create CE op 5.394454\n",
      "16:59:56 Instantiating cohort cohort_1944\n",
      "16:59:56 Generating 30 years from 1944\n",
      "16:59:56 Create ce op with gamma: 8.000000\n",
      "16:59:56 Create CE op 5.105430\n",
      "16:59:56 Instantiating cohort cohort_1945\n",
      "16:59:56 Generating 30 years from 1945\n",
      "16:59:56 Create ce op with gamma: 8.000000\n",
      "16:59:56 Create CE op 4.911167\n",
      "16:59:57 Instantiating cohort cohort_1946\n",
      "16:59:57 Generating 30 years from 1946\n",
      "16:59:57 Create ce op with gamma: 8.000000\n",
      "16:59:57 Create CE op 4.456034\n",
      "16:59:57 Instantiating cohort cohort_1947\n",
      "16:59:57 Generating 30 years from 1947\n",
      "16:59:57 Create ce op with gamma: 8.000000\n",
      "16:59:57 Create CE op 5.234968\n",
      "16:59:57 Instantiating cohort cohort_1948\n",
      "16:59:57 Generating 30 years from 1948\n",
      "16:59:58 Create ce op with gamma: 8.000000\n",
      "16:59:58 Create CE op 5.645485\n",
      "16:59:58 Instantiating cohort cohort_1949\n",
      "16:59:58 Generating 30 years from 1949\n",
      "16:59:58 Create ce op with gamma: 8.000000\n",
      "16:59:58 Create CE op 6.040702\n",
      "16:59:58 Instantiating cohort cohort_1950\n",
      "16:59:58 Generating 30 years from 1950\n",
      "16:59:58 Create ce op with gamma: 8.000000\n",
      "16:59:58 Create CE op 5.975190\n",
      "16:59:59 Instantiating cohort cohort_1951\n",
      "16:59:59 Generating 30 years from 1951\n",
      "16:59:59 Create ce op with gamma: 8.000000\n",
      "16:59:59 Create CE op 5.817038\n",
      "16:59:59 Instantiating cohort cohort_1952\n",
      "16:59:59 Generating 30 years from 1952\n",
      "16:59:59 Create ce op with gamma: 8.000000\n",
      "16:59:59 Create CE op 5.819612\n",
      "16:59:59 Instantiating cohort cohort_1953\n",
      "16:59:59 Generating 30 years from 1953\n",
      "16:59:59 Create ce op with gamma: 8.000000\n",
      "16:59:59 Create CE op 5.778506\n",
      "17:00:00 Instantiating cohort cohort_1954\n",
      "17:00:00 Generating 30 years from 1954\n",
      "17:00:00 Create ce op with gamma: 8.000000\n",
      "17:00:00 Create CE op 6.491792\n",
      "17:00:00 Instantiating cohort cohort_1955\n",
      "17:00:00 Generating 30 years from 1955\n",
      "17:00:00 Create ce op with gamma: 8.000000\n",
      "17:00:00 Create CE op 5.528992\n",
      "17:00:01 Instantiating cohort cohort_1956\n",
      "17:00:01 Generating 30 years from 1956\n",
      "17:00:01 Create ce op with gamma: 8.000000\n",
      "17:00:01 Create CE op 4.970847\n",
      "17:00:01 Instantiating cohort cohort_1957\n",
      "17:00:01 Generating 30 years from 1957\n",
      "17:00:01 Create ce op with gamma: 8.000000\n",
      "17:00:01 Create CE op 5.029950\n",
      "17:00:01 Instantiating cohort cohort_1958\n",
      "17:00:01 Generating 30 years from 1958\n",
      "17:00:02 Create ce op with gamma: 8.000000\n",
      "17:00:02 Create CE op 5.661326\n",
      "17:00:02 Instantiating cohort cohort_1959\n",
      "17:00:02 Generating 30 years from 1959\n",
      "17:00:02 Create ce op with gamma: 8.000000\n",
      "17:00:02 Create CE op 4.797619\n",
      "17:00:02 Instantiating cohort cohort_1960\n",
      "17:00:02 Generating 30 years from 1960\n",
      "17:00:03 Create ce op with gamma: 8.000000\n",
      "17:00:03 Create CE op 4.655229\n",
      "17:00:03 Instantiating cohort cohort_1961\n",
      "17:00:03 Generating 30 years from 1961\n",
      "17:00:03 Create ce op with gamma: 8.000000\n",
      "17:00:03 Create CE op 4.721407\n",
      "17:00:03 Instantiating cohort cohort_1962\n",
      "17:00:03 Generating 30 years from 1962\n",
      "17:00:03 Create ce op with gamma: 8.000000\n",
      "17:00:03 Create CE op 4.198353\n",
      "17:00:04 Instantiating cohort cohort_1963\n",
      "17:00:04 Generating 30 years from 1963\n",
      "17:00:04 Create ce op with gamma: 8.000000\n",
      "17:00:04 Create CE op 4.499244\n",
      "17:00:04 Instantiating cohort cohort_1964\n",
      "17:00:04 Generating 30 years from 1964\n",
      "17:00:05 Create ce op with gamma: 8.000000\n",
      "17:00:05 Create CE op 4.112266\n",
      "17:00:05 Instantiating cohort cohort_1965\n",
      "17:00:05 Generating 30 years from 1965\n",
      "17:00:05 Create ce op with gamma: 8.000000\n",
      "17:00:05 Create CE op 3.842409\n",
      "17:00:05 Instantiating cohort cohort_1966\n",
      "17:00:05 Generating 30 years from 1966\n",
      "17:00:05 Create ce op with gamma: 8.000000\n",
      "17:00:05 Create CE op 3.690863\n",
      "17:00:06 Instantiating cohort cohort_1967\n",
      "17:00:06 Generating 30 years from 1967\n",
      "17:00:06 Create ce op with gamma: 8.000000\n",
      "17:00:06 Create CE op 4.017470\n",
      "17:00:06 Instantiating cohort cohort_1968\n",
      "17:00:06 Generating 30 years from 1968\n",
      "17:00:06 Create ce op with gamma: 8.000000\n",
      "17:00:06 Create CE op 3.719474\n",
      "17:00:07 Instantiating cohort cohort_1969\n",
      "17:00:07 Generating 30 years from 1969\n",
      "17:00:07 Create ce op with gamma: 8.000000\n",
      "17:00:07 Create CE op 3.659766\n",
      "17:00:07 Instantiating cohort cohort_1970\n",
      "17:00:07 Generating 30 years from 1970\n",
      "17:00:07 Create ce op with gamma: 8.000000\n",
      "17:00:07 Create CE op 4.009532\n",
      "17:00:08 Instantiating cohort cohort_1971\n",
      "17:00:08 Generating 30 years from 1971\n",
      "17:00:08 Create ce op with gamma: 8.000000\n",
      "17:00:08 Create CE op 4.044391\n",
      "17:00:08 Instantiating cohort cohort_1972\n",
      "17:00:08 Generating 30 years from 1972\n",
      "17:00:08 Create ce op with gamma: 8.000000\n",
      "17:00:08 Create CE op 3.889541\n",
      "17:00:09 Instantiating cohort cohort_1973\n",
      "17:00:09 Generating 30 years from 1973\n",
      "17:00:09 Create ce op with gamma: 8.000000\n",
      "17:00:09 Create CE op 3.706021\n",
      "17:00:09 Instantiating cohort cohort_1974\n",
      "17:00:09 Generating 30 years from 1974\n",
      "17:00:09 Create ce op with gamma: 8.000000\n",
      "17:00:09 Create CE op 4.153282\n",
      "17:00:10 Instantiating cohort cohort_1975\n",
      "17:00:10 Generating 30 years from 1975\n",
      "17:00:10 Create ce op with gamma: 8.000000\n",
      "17:00:10 Create CE op 5.262786\n",
      "17:00:11 Instantiating cohort cohort_1976\n",
      "17:00:11 Generating 30 years from 1976\n",
      "17:00:11 Create ce op with gamma: 8.000000\n",
      "17:00:11 Create CE op 4.808366\n",
      "17:00:11 Instantiating cohort cohort_1977\n",
      "17:00:11 Generating 30 years from 1977\n",
      "17:00:11 Create ce op with gamma: 8.000000\n",
      "17:00:11 Create CE op 4.517707\n",
      "17:00:12 Instantiating cohort cohort_1978\n",
      "17:00:12 Generating 30 years from 1978\n",
      "17:00:12 Create ce op with gamma: 8.000000\n",
      "17:00:12 Create CE op 4.928438\n",
      "17:00:12 Instantiating cohort cohort_1979\n",
      "17:00:12 Generating 30 years from 1979\n",
      "17:00:12 Create ce op with gamma: 8.000000\n",
      "17:00:12 Create CE op 5.196985\n",
      "17:00:13 Instantiating cohort cohort_1980\n",
      "17:00:13 Generating 30 years from 1980\n",
      "17:00:13 Create ce op with gamma: 8.000000\n",
      "17:00:13 Create CE op 5.356443\n",
      "17:00:13 Instantiating cohort cohort_1981\n",
      "17:00:13 Generating 30 years from 1981\n",
      "17:00:14 Create ce op with gamma: 8.000000\n",
      "17:00:14 Create CE op 5.221420\n",
      "17:00:14 Instantiating cohort cohort_1982\n",
      "17:00:14 Generating 30 years from 1982\n",
      "17:00:14 Create ce op with gamma: 8.000000\n",
      "17:00:14 Create CE op 5.940978\n",
      "17:00:15 Instantiating cohort cohort_1983\n",
      "17:00:15 Generating 30 years from 1983\n",
      "17:00:15 Create ce op with gamma: 8.000000\n",
      "17:00:15 Create CE op 5.776562\n",
      "17:00:15 Instantiating cohort cohort_1984\n",
      "17:00:15 Generating 30 years from 1984\n",
      "17:00:15 Create ce op with gamma: 8.000000\n",
      "17:00:15 Create CE op 5.682128\n",
      "17:00:16 Instantiating cohort cohort_1985\n",
      "17:00:16 Generating 30 years from 1985\n",
      "17:00:16 Create ce op with gamma: 8.000000\n",
      "17:00:16 Create CE op 6.020979\n",
      "17:00:16 Instantiating cohort cohort_1986\n",
      "17:00:16 Generating 30 years from 1986\n",
      "17:00:17 Create ce op with gamma: 8.000000\n",
      "17:00:17 Create CE op 5.593521\n",
      "17:00:17 Summary by cohort\n",
      "      mean_spend   sd_spend  min_spend   max_spend  total_spend        ce\n",
      "1928    7.103008   6.346463   3.609243   37.559135   213.090225  4.643645\n",
      "1929    4.931037   2.850893   3.220363   18.891738   147.931102  3.927663\n",
      "1930    5.925849   4.854840   3.295279   29.700473   177.775481  4.117642\n",
      "1931    7.924386   8.582596   3.465120   49.803788   237.731583  4.503485\n",
      "1932   13.610733  20.455730   3.996189  115.859799   408.321990  5.587242\n",
      "1933   13.847575  19.429963   4.570448  108.115107   415.427255  5.790120\n",
      "1934    9.919830  12.572192   3.899031   71.789912   297.594889  4.851973\n",
      "1935   11.235387  15.423238   4.081657   87.596596   337.061613  5.020730\n",
      "1936    8.024943   9.134418   3.547464   52.765278   240.748289  4.284851\n",
      "1937    5.975075   4.725102   3.253967   27.792250   179.252244  3.845672\n",
      "1938   11.590917  15.091473   3.788194   84.922410   347.727496  4.761143\n",
      "1939    8.999374  10.204098   3.442112   58.120192   269.981217  4.256801\n",
      "1940    9.476911   9.838279   3.449368   54.558966   284.307321  4.314835\n",
      "1941   11.468200  12.702490   3.570599   70.703614   344.046006  4.581398\n",
      "1942   16.791024  21.436332   4.034989  119.916818   503.730721  5.360601\n",
      "1943   16.966374  22.265720   4.217314  125.724308   508.991217  5.394454\n",
      "1944   14.330796  15.489738   3.987815   85.468515   429.923870  5.105430\n",
      "1945   12.222867   9.913253   3.775813   51.797070   366.686011  4.911167\n",
      "1946    9.603656   7.283004   3.436568   41.698092   288.109680  4.456034\n",
      "1947   14.384591  13.997187   3.843206   81.213358   431.537743  5.234968\n",
      "1948   15.646485  14.076276   3.950559   80.770604   469.394562  5.645485\n",
      "1949   15.852519  13.379560   4.215325   77.623040   475.575580  6.040702\n",
      "1950   13.773480  10.645199   4.240157   63.358408   413.204408  5.975190\n",
      "1951   11.935441   8.866539   4.139393   54.428916   358.063222  5.817038\n",
      "1952   10.697537   6.745577   4.134621   42.166271   320.926105  5.819612\n",
      "1953    9.793289   6.527503   3.900066   42.029831   293.798655  5.778506\n",
      "1954   10.492669   7.875785   4.657248   50.182212   314.780058  6.491792\n",
      "1955    7.422228   4.141696   4.186486   28.060199   222.666846  5.528992\n",
      "1956    6.114897   3.000229   3.779466   21.364709   183.446907  4.970847\n",
      "1957    6.335115   3.810415   3.745804   25.857817   190.053451  5.029950\n",
      "1958    7.563460   5.607652   4.478531   35.657479   226.903813  5.661326\n",
      "1959    5.707103   2.884216   4.044702   20.069798   171.213076  4.797619\n",
      "1960    5.587263   3.113681   3.933558   21.367040   167.617891  4.655229\n",
      "1961    5.789478   3.284632   4.021656   21.814771   173.684353  4.721407\n",
      "1962    4.805286   1.943842   3.627647   14.397159   144.158577  4.198353\n",
      "1963    5.698170   3.630369   3.787890   23.631695   170.945089  4.499244\n",
      "1964    4.886873   2.291664   3.516002   16.010685   146.606204  4.112266\n",
      "1965    4.288050   1.201389   3.339557    9.565156   128.641501  3.842409\n",
      "1966    4.047540   1.009610   3.237003    8.655287   121.426207  3.690863\n",
      "1967    5.308811   3.653913   3.403824   23.385678   159.264336  4.017470\n",
      "1968    4.565352   2.489663   3.220999   16.893296   136.960556  3.719474\n",
      "1969    4.678672   3.063094   3.174779   19.978332   140.360170  3.659766\n",
      "1970    6.910801   8.185465   3.350516   47.763073   207.324042  4.009532\n",
      "1971    7.532961   8.958852   3.351297   50.877442   225.988815  4.044391\n",
      "1972    6.879558   6.971568   3.247201   39.305564   206.386744  3.889541\n",
      "1973    5.921728   4.622463   3.134198   26.011757   177.651843  3.706021\n",
      "1974    9.354891  10.972260   3.363042   61.334286   280.646717  4.153282\n",
      "1975   17.872324  26.009169   4.299000  143.101514   536.169727  5.262786\n",
      "1976   14.590081  19.457642   3.888588  107.437121   437.702437  4.808366\n",
      "1977   12.856045  16.620105   3.627015   93.068867   385.681349  4.517707\n",
      "1978   16.532428  22.528160   3.853002  125.330292   495.972849  4.928438\n",
      "1979   17.773045  21.145701   3.938639  113.758951   533.191350  5.196985\n",
      "1980   18.634246  22.891358   3.915696  127.109058   559.027393  5.356443\n",
      "1981   17.419744  21.721699   3.728327  122.761078   522.592316  5.221420\n",
      "1982   21.479058  27.699562   4.230340  156.191132   644.371746  5.940978\n",
      "1983   19.112005  24.656700   4.168397  140.470198   573.360148  5.776562\n",
      "1984   17.957604  24.395430   3.976096  140.142303   538.728127  5.682128\n",
      "1985   19.044310  27.139533   4.357432  155.328991   571.329286  6.020979\n",
      "1986   15.596985  20.404056   4.206998  116.379295   467.909551  5.593521\n",
      "    spend_mean   spend_sd  spend_min   spend_max\n",
      "0     4.030408   0.298318   3.363042    4.657248\n",
      "1     4.129680   0.437146   3.134198    5.285261\n",
      "2     4.229364   0.522057   3.220363    5.401103\n",
      "3     4.354657   0.657713   3.244310    6.217383\n",
      "4     4.491963   0.756426   3.253967    6.378949\n",
      "5     4.649857   0.865255   3.174779    6.886115\n",
      "6     4.818928   1.036802   3.220999    7.744866\n",
      "7     5.012877   1.211305   3.316392    7.947275\n",
      "8     5.188269   1.328391   3.177389    8.098496\n",
      "9     5.398312   1.527354   3.273882    9.219797\n",
      "10    5.670773   1.777047   3.254359    9.830153\n",
      "11    5.976920   2.071741   3.308724   10.264965\n",
      "12    6.327206   2.408398   3.186369   11.858104\n",
      "13    6.728654   2.831714   3.239022   13.537225\n",
      "14    7.144893   3.224169   3.386575   15.083094\n",
      "15    7.567687   3.609645   3.237003   16.112155\n",
      "16    8.030148   4.051538   3.364358   19.321692\n",
      "17    8.531063   4.419612   3.481640   21.741202\n",
      "18    9.046367   4.776763   3.489725   21.351997\n",
      "19    9.605672   5.098866   3.680113   21.965542\n",
      "20   10.253281   5.447986   3.994624   22.581419\n",
      "21   10.993393   5.870603   3.937472   22.499508\n",
      "22   11.788984   6.358721   4.062717   24.836824\n",
      "23   12.703260   6.957020   4.424327   27.235292\n",
      "24   13.721394   7.505990   4.292667   31.673663\n",
      "25   14.984045   8.078475   4.727285   34.160823\n",
      "26   16.695166   8.775084   4.885216   34.730011\n",
      "27   19.310819  10.301901   5.180413   40.852131\n",
      "28   23.972998  13.573035   5.215851   53.220372\n",
      "29   65.383673  42.556422   8.655287  156.191132\n",
      "17:00:37 Create optimizer class\n",
      "17:00:37 Run variable initializers\n",
      "17:00:37 Create cost ops\n",
      "17:00:37 Sum 59 ce ops\n",
      "17:00:37 Create ce op with gamma: 8.000000\n",
      "17:00:37 Create CE op 4.458856\n",
      "17:00:38 Total CE spend, all cohorts: 4.458856\n",
      "17:00:38 Raw cost objective: -4.458856\n",
      "17:00:39 Add soft constraint penalty if stock alloc < 0: -4.458856\n",
      "17:00:40 Add soft constraint penalty if stock alloc > 1: -4.458856\n",
      "17:00:40 Add soft constraint penalty if var spending < 0: -4.458856\n",
      "17:00:41 Add soft constraint if const spending < 0: -4.458856\n",
      "17:00:42 Add soft constraint if stock alloc increases in any year: -4.458856\n",
      "17:00:43 All inclusive objective to be minimized: -4.458856\n",
      "17:00:43 Objective: 4.458856\n",
      "17:00:43 Constant spending: 2.250000\n",
      "17:00:43 Variable spending by year\n",
      "[0.016666666666666666, 0.017241379310344827, 0.017857142857142856, 0.018518518518518517, 0.019230769230769232, 0.02, 0.020833333333333332, 0.021739130434782608, 0.022727272727272728, 0.023809523809523808, 0.025000000000000001, 0.026315789473684209, 0.027777777777777776, 0.029411764705882353, 0.03125, 0.033333333333333333, 0.035714285714285712, 0.038461538461538464, 0.041666666666666664, 0.045454545454545456, 0.050000000000000003, 0.055555555555555552, 0.0625, 0.071428571428571425, 0.083333333333333329, 0.10000000000000001, 0.125, 0.16666666666666666, 0.25, 1.0]\n",
      "17:00:43 Stock allocation by year\n",
      "[0.81999999999999995, 0.81499999999999995, 0.80999999999999994, 0.80499999999999994, 0.79999999999999993, 0.79499999999999993, 0.78999999999999992, 0.78499999999999992, 0.77999999999999992, 0.77499999999999991, 0.76999999999999991, 0.7649999999999999, 0.76000000000000001, 0.75499999999999989, 0.75, 0.745, 0.73999999999999999, 0.73499999999999999, 0.72999999999999998, 0.72499999999999998, 0.71999999999999997, 0.71499999999999997, 0.70999999999999996, 0.70499999999999996, 0.69999999999999996, 0.69499999999999995, 0.68999999999999995, 0.68499999999999994, 0.67999999999999994, 0.67499999999999993]\n",
      "17:00:43 Create optimizer (learning rate 0.000000100000)\n",
      "17:02:38 Create optimizer op and run 1 steps\n",
      "!\n",
      "17:03:47 step 1 objective 4.458879 best 4.458879 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:04:04 step 50 objective 4.460002 best 4.460002 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:04:21 step 100 objective 4.461141 best 4.461141 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:04:39 step 150 objective 4.462272 best 4.462272 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:04:56 step 200 objective 4.463396 best 4.463396 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:05:14 step 250 objective 4.464512 best 4.464512 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:05:32 step 300 objective 4.465621 best 4.465621 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:05:50 step 350 objective 4.466723 best 4.466723 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:06:08 step 400 objective 4.467818 best 4.467818 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:06:26 step 450 objective 4.468906 best 4.468906 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:06:43 step 500 objective 4.469986 best 4.469986 (0 steps ago)\n",
      "\n",
      "#Objective: 4.469986\n",
      "\n",
      "const_spend = 2.250045\n",
      "var_spend_pcts = pd.Series([0.016981335876774507, 0.01753718461994427, 0.018125161393792551, 0.018757796228375718, 0.019441035324328344, 0.020185792696601316, 0.020999638615269815, 0.021893671318928196, 0.022870129134530268, 0.023943468108949949, 0.025126168316832734, 0.026434223234711233, 0.02788709594833165, 0.029506848953520338, 0.03132978813047213, 0.033399898851006901, 0.035769654496830505, 0.038508284458233746, 0.041704912344424007, 0.045484464761701059, 0.050020857798064963, 0.055570257101994522, 0.062510223343744897, 0.071434606763024863, 0.083337105343287463, 0.10000211310503587, 0.12500100215239435, 0.1666670587501137, 0.25000018341586572, 1.0])\n",
      "stock_allocations = pd.Series([0.81999505329844669, 0.81499564401017588, 0.80999893987036375, 0.80500069224129778, 0.79999969813080019, 0.79499946443183456, 0.79000248543627927, 0.78500151644403038, 0.77999786705556029, 0.77499999161479649, 0.77000140708133724, 0.7650009353201479, 0.7600004678684863, 0.75500141726793246, 0.75000193365630519, 0.74500100437613315, 0.74000045660089098, 0.73500025058595186, 0.73000040258180288, 0.72500029604118144, 0.72000019132897541, 0.71500022882531822, 0.71000011261732343, 0.7050001180941049, 0.70000000429658205, 0.69500002568291697, 0.69000001191192306, 0.68500000233745462, 0.68000000240562164, 0.67500000021087914])\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:07:01 step 550 objective 4.471060 best 4.471060 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:07:19 step 600 objective 4.472128 best 4.472128 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:07:36 step 650 objective 4.473188 best 4.473188 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:07:54 step 700 objective 4.474242 best 4.474242 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:08:11 step 750 objective 4.475289 best 4.475289 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:08:29 step 800 objective 4.476330 best 4.476330 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:08:46 step 850 objective 4.477365 best 4.477365 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:09:04 step 900 objective 4.478393 best 4.478393 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:09:22 step 950 objective 4.479415 best 4.479415 (0 steps ago)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "17:09:39 step 1000 objective 4.480430 best 4.480430 (0 steps ago)\n",
      "\n",
      "#Objective: 4.480430\n",
      "\n",
      "const_spend = 2.250089\n",
      "var_spend_pcts = pd.Series([0.01727675440035106, 0.017817560995146049, 0.018381596078205449, 0.018988649019389039, 0.019645630054706226, 0.020367968379909469, 0.021163680459632857, 0.022046831317305084, 0.023012360299239806, 0.024077331020203315, 0.025252672936000371, 0.026553336781926635, 0.027997374915982851, 0.029603087172416914, 0.031410811212382143, 0.033467688154962219, 0.035826190569656149, 0.038556130793743482, 0.041744147564336032, 0.045515229320861522, 0.050042366737522818, 0.05558545465585786, 0.062520815964177023, 0.071440879979146776, 0.083341037044326521, 0.1000043241902136, 0.12500205631806946, 0.16666747421069369, 0.25000037990091484, 1.0])\n",
      "stock_allocations = pd.Series([0.81999002547362465, 0.81499122505313615, 0.80999786340179281, 0.80500140391839026, 0.79999936984826547, 0.79499889118419964, 0.79000502616558876, 0.78500306046018564, 0.77999564675810928, 0.77499998271917281, 0.77000285692874249, 0.76500189530999319, 0.76000094779772909, 0.75500287921104325, 0.75000393439276258, 0.74500204031574102, 0.74000092605595547, 0.73500051137613753, 0.73000081965825092, 0.72500060363804264, 0.72000038998425731, 0.71500046776863146, 0.71000023078230723, 0.70500024220913482, 0.70000000851455035, 0.69500005301696388, 0.6900000245631821, 0.68500000479693446, 0.68000000501887559, 0.67500000045639597])\n",
      "\n",
      "!!"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0000001\n",
    "fileprefix = \"gamma_8\"\n",
    "picklefile = '%s.pickle' % fileprefix\n",
    "csvfile = \"summary_%s.csv\" % fileprefix\n",
    "yearsfile = \"years_%s.csv\" % fileprefix\n",
    "returnsfile = \"retyears_%s.csv\" % fileprefix\n",
    "\n",
    "\n",
    "max_steps_unimproved = 500\n",
    "gamma = 8\n",
    "\n",
    "print('%s Start optimization session' % strftime(\"%H:%M:%S\"))\n",
    "print('%s learning_rate: %.12f steps %d picklefile %s' % (strftime(\"%H:%M:%S\"), learning_rate, max_steps_unimproved, picklefile))\n",
    "\n",
    "#print(\"opening picklefile %s\" % picklefile)\n",
    "#const_spend, var_spend_pcts, stock_allocations, bond_allocations  = pickle.load( open(picklefile, \"rb\" ) )\n",
    "\n",
    "print (\"const spend: %f\" % const_spend)\n",
    "print (\"variable spend:\")\n",
    "print (var_spend_pcts)\n",
    "print (\"stock allocation:\" )\n",
    "print (stock_allocations)\n",
    "\n",
    "model = SafeWithdrawalModel(returns_list = [real_stocks, real_bonds],\n",
    "                            names_list = [\"stocks\",\"bonds\"],\n",
    "                            allocations_list = [stock_allocations, bond_allocations],\n",
    "                            start_val = 100.0,\n",
    "                            const_spend = const_spend,\n",
    "                            var_spend_pcts = var_spend_pcts,\n",
    "                            gamma = gamma,\n",
    "                            survival=None\n",
    ")\n",
    "\n",
    "# generate cohorts\n",
    "model.cohort_history = CohortHistory(model)\n",
    "\n",
    "print('%s Summary by cohort' % strftime(\"%H:%M:%S\"))\n",
    "print(model.cohort_history.as_dataframe())\n",
    "all_years = model.cohort_history.spend_by_year()\n",
    "all_years.to_csv(yearsfile, format=\"%.18f\")\n",
    "ret_years = model.cohort_history.returns_by_year()\n",
    "ret_years.to_csv(returnsfile, format=\"%.18f\")\n",
    "\n",
    "summary = model.cohort_history.summarize_by_year()\n",
    "print(summary)\n",
    "summary.to_csv(csvfile, format=\"%.18f\")\n",
    "\n",
    "# run optimizer\n",
    "# set an initial learning rate that improves objective by a reasonable amount each step\n",
    "\n",
    "model.optimizer = CohortHistoryOptimize(model)\n",
    "model.optimizer.optimize(learning_rate, steps=1)\n",
    "\n",
    "# continue optimizing without re-initializing vars or optimizer\n",
    "# reduce learning rate if no improvement for a while\n",
    "# end when learning rate is too small to make significant improvement\n",
    "\n",
    "max_steps = 1001 # don't run for hours because notebook will eventually crash\n",
    "report_steps = 50\n",
    "learning_rate = model.optimizer.learning_rate\n",
    "\n",
    "for i in range(max_steps):\n",
    "    model.optimizer.run_step(report_steps=report_steps)\n",
    "    if model.optimizer.steps_ago >= max_steps_unimproved: # no improvement for too long\n",
    "        break\n",
    "\n",
    "const_spend = model.optimizer.best_const_spend\n",
    "var_spend_pcts = pd.Series(model.optimizer.best_var_spend)\n",
    "stock_allocations = pd.Series(model.optimizer.best_stock_alloc)\n",
    "bond_allocations   = 1 - stock_allocations\n",
    "pickle_list = [const_spend, var_spend_pcts, stock_allocations, bond_allocations]\n",
    "pickle.dump( pickle_list, open( picklefile, \"wb\" ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:15:56 Create TensorFlow graph and session\n",
      "18:15:56 Create constants stocks_return\n",
      "18:15:56 Create constants bonds_return\n",
      "18:15:56 Create variables stocks_alloc\n",
      "18:15:56 Create ops for soft constraint alloc_min_0 > 0\n",
      "18:15:57 Create ops for soft constraint alloc_max_1 < 1\n",
      "18:15:57 Create ops for soft constraint, declining stock alloc alloc_decrease\n",
      "18:15:57 Create ops for bonds_alloc\n",
      "18:15:57 Create variables var_spend\n",
      "18:15:57 Create ops for soft constraint vspend_min_0 > 0\n",
      "18:15:57 Create cohort history, years 1928 to 1986\n",
      "18:15:57 Instantiating cohort cohort_1928\n",
      "18:15:57 Generating 30 years from 1928\n",
      "18:15:57 Create ce op with gamma: 8.000000\n",
      "18:15:58 Create CE op 5.009001\n",
      "18:15:58 Instantiating cohort cohort_1929\n",
      "18:15:58 Generating 30 years from 1929\n",
      "18:15:58 Create ce op with gamma: 8.000000\n",
      "18:15:58 Create CE op 4.101096\n",
      "18:15:58 Instantiating cohort cohort_1930\n",
      "18:15:58 Generating 30 years from 1930\n",
      "18:15:58 Create ce op with gamma: 8.000000\n",
      "18:15:58 Create CE op 4.385080\n",
      "18:15:58 Instantiating cohort cohort_1931\n",
      "18:15:58 Generating 30 years from 1931\n",
      "18:15:59 Create ce op with gamma: 8.000000\n",
      "18:15:59 Create CE op 4.907650\n",
      "18:15:59 Instantiating cohort cohort_1932\n",
      "18:15:59 Generating 30 years from 1932\n",
      "18:15:59 Create ce op with gamma: 8.000000\n",
      "18:15:59 Create CE op 6.291063\n",
      "18:15:59 Instantiating cohort cohort_1933\n",
      "18:15:59 Generating 30 years from 1933\n",
      "18:15:59 Create ce op with gamma: 8.000000\n",
      "18:15:59 Create CE op 6.503586\n",
      "18:15:59 Instantiating cohort cohort_1934\n",
      "18:15:59 Generating 30 years from 1934\n",
      "18:16:00 Create ce op with gamma: 8.000000\n",
      "18:16:00 Create CE op 5.318936\n",
      "18:16:00 Instantiating cohort cohort_1935\n",
      "18:16:00 Generating 30 years from 1935\n",
      "18:16:00 Create ce op with gamma: 8.000000\n",
      "18:16:00 Create CE op 5.523782\n",
      "18:16:00 Instantiating cohort cohort_1936\n",
      "18:16:00 Generating 30 years from 1936\n",
      "18:16:00 Create ce op with gamma: 8.000000\n",
      "18:16:00 Create CE op 4.629684\n",
      "18:16:01 Instantiating cohort cohort_1937\n",
      "18:16:01 Generating 30 years from 1937\n",
      "18:16:01 Create ce op with gamma: 8.000000\n",
      "18:16:01 Create CE op 4.101820\n",
      "18:16:01 Instantiating cohort cohort_1938\n",
      "18:16:01 Generating 30 years from 1938\n",
      "18:16:01 Create ce op with gamma: 8.000000\n",
      "18:16:01 Create CE op 5.259903\n",
      "18:16:02 Instantiating cohort cohort_1939\n",
      "18:16:02 Generating 30 years from 1939\n",
      "18:16:02 Create ce op with gamma: 8.000000\n",
      "18:16:02 Create CE op 4.644477\n",
      "18:16:02 Instantiating cohort cohort_1940\n",
      "18:16:02 Generating 30 years from 1940\n",
      "18:16:02 Create ce op with gamma: 8.000000\n",
      "18:16:02 Create CE op 4.730322\n",
      "18:16:03 Instantiating cohort cohort_1941\n",
      "18:16:03 Generating 30 years from 1941\n",
      "18:16:03 Create ce op with gamma: 8.000000\n",
      "18:16:03 Create CE op 5.074596\n",
      "18:16:03 Instantiating cohort cohort_1942\n",
      "18:16:03 Generating 30 years from 1942\n",
      "18:16:03 Create ce op with gamma: 8.000000\n",
      "18:16:03 Create CE op 6.057469\n",
      "18:16:04 Instantiating cohort cohort_1943\n",
      "18:16:04 Generating 30 years from 1943\n",
      "18:16:04 Create ce op with gamma: 8.000000\n",
      "18:16:04 Create CE op 6.094438\n",
      "18:16:04 Instantiating cohort cohort_1944\n",
      "18:16:04 Generating 30 years from 1944\n",
      "18:16:04 Create ce op with gamma: 8.000000\n",
      "18:16:04 Create CE op 5.733202\n",
      "18:16:05 Instantiating cohort cohort_1945\n",
      "18:16:05 Generating 30 years from 1945\n",
      "18:16:05 Create ce op with gamma: 8.000000\n",
      "18:16:05 Create CE op 5.496141\n",
      "18:16:05 Instantiating cohort cohort_1946\n",
      "18:16:05 Generating 30 years from 1946\n",
      "18:16:05 Create ce op with gamma: 8.000000\n",
      "18:16:05 Create CE op 4.930538\n",
      "18:16:06 Instantiating cohort cohort_1947\n",
      "18:16:06 Generating 30 years from 1947\n",
      "18:16:06 Create ce op with gamma: 8.000000\n",
      "18:16:06 Create CE op 5.933276\n",
      "18:16:06 Instantiating cohort cohort_1948\n",
      "18:16:06 Generating 30 years from 1948\n",
      "18:16:06 Create ce op with gamma: 8.000000\n",
      "18:16:06 Create CE op 6.460368\n",
      "18:16:07 Instantiating cohort cohort_1949\n",
      "18:16:07 Generating 30 years from 1949\n",
      "18:16:07 Create ce op with gamma: 8.000000\n",
      "18:16:07 Create CE op 6.974174\n",
      "18:16:07 Instantiating cohort cohort_1950\n",
      "18:16:07 Generating 30 years from 1950\n",
      "18:16:08 Create ce op with gamma: 8.000000\n",
      "18:16:08 Create CE op 6.888516\n",
      "18:16:08 Instantiating cohort cohort_1951\n",
      "18:16:08 Generating 30 years from 1951\n",
      "18:16:08 Create ce op with gamma: 8.000000\n",
      "18:16:08 Create CE op 6.677662\n",
      "18:16:09 Instantiating cohort cohort_1952\n",
      "18:16:09 Generating 30 years from 1952\n",
      "18:16:09 Create ce op with gamma: 8.000000\n",
      "18:16:09 Create CE op 6.668467\n",
      "18:16:09 Instantiating cohort cohort_1953\n",
      "18:16:09 Generating 30 years from 1953\n",
      "18:16:09 Create ce op with gamma: 8.000000\n",
      "18:16:09 Create CE op 6.583520\n",
      "18:16:10 Instantiating cohort cohort_1954\n",
      "18:16:10 Generating 30 years from 1954\n",
      "18:16:10 Create ce op with gamma: 8.000000\n",
      "18:16:10 Create CE op 7.472197\n",
      "18:16:10 Instantiating cohort cohort_1955\n",
      "18:16:10 Generating 30 years from 1955\n",
      "18:16:11 Create ce op with gamma: 8.000000\n",
      "18:16:11 Create CE op 6.131490\n",
      "18:16:11 Instantiating cohort cohort_1956\n",
      "18:16:11 Generating 30 years from 1956\n",
      "18:16:11 Create ce op with gamma: 8.000000\n",
      "18:16:11 Create CE op 5.321761\n",
      "18:16:12 Instantiating cohort cohort_1957\n",
      "18:16:12 Generating 30 years from 1957\n",
      "18:16:12 Create ce op with gamma: 8.000000\n",
      "18:16:12 Create CE op 5.361237\n",
      "18:16:12 Instantiating cohort cohort_1958\n",
      "18:16:12 Generating 30 years from 1958\n",
      "18:16:13 Create ce op with gamma: 8.000000\n",
      "18:16:13 Create CE op 6.094594\n",
      "18:16:13 Instantiating cohort cohort_1959\n",
      "18:16:13 Generating 30 years from 1959\n",
      "18:16:13 Create ce op with gamma: 8.000000\n",
      "18:16:13 Create CE op 4.954271\n",
      "18:16:14 Instantiating cohort cohort_1960\n",
      "18:16:14 Generating 30 years from 1960\n",
      "18:16:14 Create ce op with gamma: 8.000000\n",
      "18:16:14 Create CE op 4.776584\n",
      "18:16:14 Instantiating cohort cohort_1961\n",
      "18:16:14 Generating 30 years from 1961\n",
      "18:16:15 Create ce op with gamma: 8.000000\n",
      "18:16:15 Create CE op 4.868335\n",
      "18:16:15 Instantiating cohort cohort_1962\n",
      "18:16:15 Generating 30 years from 1962\n",
      "18:16:15 Create ce op with gamma: 8.000000\n",
      "18:16:15 Create CE op 4.254335\n",
      "18:16:16 Instantiating cohort cohort_1963\n",
      "18:16:16 Generating 30 years from 1963\n",
      "18:16:16 Create ce op with gamma: 8.000000\n",
      "18:16:16 Create CE op 4.647785\n",
      "18:16:16 Instantiating cohort cohort_1964\n",
      "18:16:16 Generating 30 years from 1964\n",
      "18:16:17 Create ce op with gamma: 8.000000\n",
      "18:16:17 Create CE op 4.196304\n",
      "18:16:17 Instantiating cohort cohort_1965\n",
      "18:16:17 Generating 30 years from 1965\n",
      "18:16:17 Create ce op with gamma: 8.000000\n",
      "18:16:17 Create CE op 3.875830\n",
      "18:16:18 Instantiating cohort cohort_1966\n",
      "18:16:18 Generating 30 years from 1966\n",
      "18:16:18 Create ce op with gamma: 8.000000\n",
      "18:16:18 Create CE op 3.628492\n",
      "18:16:18 Instantiating cohort cohort_1967\n",
      "18:16:18 Generating 30 years from 1967\n",
      "18:16:18 Create ce op with gamma: 8.000000\n",
      "18:16:18 Create CE op 4.185619\n",
      "18:16:19 Instantiating cohort cohort_1968\n",
      "18:16:19 Generating 30 years from 1968\n",
      "18:16:19 Create ce op with gamma: 8.000000\n",
      "18:16:19 Create CE op 3.821713\n",
      "18:16:20 Instantiating cohort cohort_1969\n",
      "18:16:20 Generating 30 years from 1969\n",
      "18:16:20 Create ce op with gamma: 8.000000\n",
      "18:16:20 Create CE op 3.781185\n",
      "18:16:20 Instantiating cohort cohort_1970\n",
      "18:16:20 Generating 30 years from 1970\n",
      "18:16:21 Create ce op with gamma: 8.000000\n",
      "18:16:21 Create CE op 4.267142\n",
      "18:16:21 Instantiating cohort cohort_1971\n",
      "18:16:21 Generating 30 years from 1971\n",
      "18:16:21 Create ce op with gamma: 8.000000\n",
      "18:16:21 Create CE op 4.326978\n",
      "18:16:22 Instantiating cohort cohort_1972\n",
      "18:16:22 Generating 30 years from 1972\n",
      "18:16:22 Create ce op with gamma: 8.000000\n",
      "18:16:22 Create CE op 4.149172\n",
      "18:16:23 Instantiating cohort cohort_1973\n",
      "18:16:23 Generating 30 years from 1973\n",
      "18:16:23 Create ce op with gamma: 8.000000\n",
      "18:16:23 Create CE op 3.937792\n",
      "18:16:23 Instantiating cohort cohort_1974\n",
      "18:16:23 Generating 30 years from 1974\n",
      "18:16:24 Create ce op with gamma: 8.000000\n",
      "18:16:24 Create CE op 4.524162\n",
      "18:16:24 Instantiating cohort cohort_1975\n",
      "18:16:24 Generating 30 years from 1975\n",
      "18:16:24 Create ce op with gamma: 8.000000\n",
      "18:16:24 Create CE op 5.917305\n",
      "18:16:25 Instantiating cohort cohort_1976\n",
      "18:16:25 Generating 30 years from 1976\n",
      "18:16:25 Create ce op with gamma: 8.000000\n",
      "18:16:25 Create CE op 5.354659\n",
      "18:16:26 Instantiating cohort cohort_1977\n",
      "18:16:26 Generating 30 years from 1977\n",
      "18:16:26 Create ce op with gamma: 8.000000\n",
      "18:16:26 Create CE op 5.001452\n",
      "18:16:27 Instantiating cohort cohort_1978\n",
      "18:16:27 Generating 30 years from 1978\n",
      "18:16:27 Create ce op with gamma: 8.000000\n",
      "18:16:27 Create CE op 5.531664\n",
      "18:16:27 Instantiating cohort cohort_1979\n",
      "18:16:27 Generating 30 years from 1979\n",
      "18:16:28 Create ce op with gamma: 8.000000\n",
      "18:16:28 Create CE op 5.880325\n",
      "18:16:28 Instantiating cohort cohort_1980\n",
      "18:16:28 Generating 30 years from 1980\n",
      "18:16:28 Create ce op with gamma: 8.000000\n",
      "18:16:28 Create CE op 6.087457\n",
      "18:16:29 Instantiating cohort cohort_1981\n",
      "18:16:29 Generating 30 years from 1981\n",
      "18:16:29 Create ce op with gamma: 8.000000\n",
      "18:16:29 Create CE op 5.914140\n",
      "18:16:30 Instantiating cohort cohort_1982\n",
      "18:16:30 Generating 30 years from 1982\n",
      "18:16:30 Create ce op with gamma: 8.000000\n",
      "18:16:30 Create CE op 6.849048\n",
      "18:16:30 Instantiating cohort cohort_1983\n",
      "18:16:30 Generating 30 years from 1983\n",
      "18:16:31 Create ce op with gamma: 8.000000\n",
      "18:16:31 Create CE op 6.630823\n",
      "18:16:31 Instantiating cohort cohort_1984\n",
      "18:16:31 Generating 30 years from 1984\n",
      "18:16:31 Create ce op with gamma: 8.000000\n",
      "18:16:31 Create CE op 6.502851\n",
      "18:16:32 Instantiating cohort cohort_1985\n",
      "18:16:32 Generating 30 years from 1985\n",
      "18:16:32 Create ce op with gamma: 8.000000\n",
      "18:16:32 Create CE op 6.944581\n",
      "18:16:33 Instantiating cohort cohort_1986\n",
      "18:16:33 Generating 30 years from 1986\n",
      "18:16:33 Create ce op with gamma: 8.000000\n",
      "18:16:33 Create CE op 6.392526\n",
      "18:16:33 Summary by cohort\n",
      "      mean_spend   sd_spend  min_spend   max_spend  total_spend        ce\n",
      "1928    6.656259   4.629544   3.981359   29.079615   199.687772  5.009001\n",
      "1929    4.584811   1.521561   3.513405   11.988434   137.544330  4.101096\n",
      "1930    5.487367   3.260889   3.631139   21.563355   164.621008  4.385080\n",
      "1931    7.338679   6.546695   3.859834   39.539090   220.160375  4.907650\n",
      "1932   12.608463  16.928782   4.560736   97.757747   378.253881  6.291063\n",
      "1933   12.837497  16.079154   5.310894   91.431448   385.124908  6.503586\n",
      "1934    9.140996  10.011862   4.405367   58.766790   274.229881  5.318936\n",
      "1935   10.321936  12.466727   4.460547   72.441371   309.658079  5.523782\n",
      "1936    7.335684   6.969580   3.842526   41.686046   220.070516  4.629684\n",
      "1937    5.469536   3.246331   3.505759   20.483550   164.086075  4.101820\n",
      "1938   10.659205  12.303429   4.209876   70.816273   319.776152  5.259903\n",
      "1939    8.260903   8.040981   3.802058   47.194390   247.827088  4.644477\n",
      "1940    8.753693   7.836025   3.834507   44.894783   262.610787  4.730322\n",
      "1941   10.649764  10.383304   3.997847   59.409195   319.492909  5.074596\n",
      "1942   15.637261  18.003723   4.610431  102.834859   469.117816  6.057469\n",
      "1943   15.801610  18.681235   4.825155  107.615218   474.048301  6.094438\n",
      "1944   13.449684  12.856106   4.449739   72.965451   403.490528  5.733202\n",
      "1945   11.590355   8.061799   4.214506   44.040285   347.710650  5.496141\n",
      "1946    9.129632   5.780349   3.800991   34.701065   273.888960  4.930538\n",
      "1947   13.702183  11.561398   4.357503   69.292939   411.065503  5.933276\n",
      "1948   15.027914  11.648493   4.499435   69.382148   450.837421  6.460368\n",
      "1949   15.355856  11.063602   4.848963   66.921175   460.675683  6.974174\n",
      "1950   13.384702   8.657159   4.881011   54.091121   401.541052  6.888516\n",
      "1951   11.638932   7.111505   4.748112   46.003012   349.167968  6.677662\n",
      "1952   10.517523   5.307079   4.737416   35.478442   315.525703  6.668467\n",
      "1953    9.639775   5.094521   4.433111   34.966106   289.193251  6.583520\n",
      "1954   10.329290   6.217734   5.431478   41.930657   309.878702  7.472197\n",
      "1955    7.307237   2.991992   4.769204   22.252428   219.217097  6.131490\n",
      "1956    5.985434   1.940110   4.268906   15.693447   179.563011  5.321761\n",
      "1957    6.172895   2.567644   4.229749   19.287755   185.186853  5.361237\n",
      "1958    7.368589   4.138053   5.195396   28.269234   221.057655  6.094594\n",
      "1959    5.529762   1.756803   4.255436   14.173949   165.892873  4.954271\n",
      "1960    5.366104   1.852506   4.055160   14.672163   160.983111  4.776584\n",
      "1961    5.560969   2.058307   4.115305   15.596219   166.829062  4.868335\n",
      "1962    4.585395   0.881578   3.621486    8.518399   137.561841  4.254335\n",
      "1963    5.401879   2.262054   3.930274   16.609074   162.056378  4.647785\n",
      "1964    4.597300   1.095716   3.578891    9.665340   137.918990  4.196304\n",
      "1965    4.035614   0.414183   3.366878    4.694566   121.068430  3.875830\n",
      "1966    3.776793   0.383309   2.945589    4.559379   113.303784  3.628492\n",
      "1967    4.898521   2.132282   3.585167   15.457932   146.955625  4.185619\n",
      "1968    4.143880   0.992431   3.343283    8.853031   124.316410  3.821713\n",
      "1969    4.204703   1.384115   3.317807   11.020279   126.141098  3.781185\n",
      "1970    6.231394   5.878410   3.626097   35.693605   186.941817  4.267142\n",
      "1971    6.783406   6.630802   3.654254   39.000437   203.502173  4.326978\n",
      "1972    6.188636   5.004277   3.517132   29.526030   185.659094  4.149172\n",
      "1973    5.364691   3.148144   3.348000   18.952280   160.940732  3.937792\n",
      "1974    8.546723   8.720267   3.724279   50.075194   256.401692  4.524162\n",
      "1975   16.377919  21.846150   4.752181  122.176145   491.337572  5.917305\n",
      "1976   13.397810  16.167849   4.261177   90.998347   401.934286  5.354659\n",
      "1977   11.834342  13.729753   3.970251   78.436751   355.030256  5.001452\n",
      "1978   15.280478  18.936921   4.297258  107.198609   458.414327  5.531664\n",
      "1979   16.536265  17.771081   4.447758   97.725750   496.087958  5.880325\n",
      "1980   17.391219  19.288898   4.447692  109.332707   521.736557  6.087457\n",
      "1981   16.318003  18.297676   4.206445  105.517413   489.540091  5.914140\n",
      "1982   20.229890  23.569299   4.870020  135.483633   606.896700  6.849048\n",
      "1983   17.998366  20.835064   4.786675  121.093337   539.950976  6.630823\n",
      "1984   16.926401  20.607988   4.533717  120.637051   507.792015  6.502851\n",
      "1985   17.960618  22.991160   5.037188  133.966137   538.818546  6.944581\n",
      "1986   14.723924  17.083926   4.834285   99.593182   441.717732  6.392526\n"
     ]
    }
   ],
   "source": [
    "# This is a good solution, objective ~4.7 after running many times at decreasing learning rates\n",
    "const_spend = 2.251680\n",
    "var_spend_pcts = pd.Series([0.022031273673441341, 0.022876165820402014, 0.023498963294297279, 0.024009923088023126, 0.024579503241692738, 0.025296781124533339, 0.026064445850974106, 0.027138692187950633, 0.02836363928583004, 0.029816306186538553, 0.03137014624414091, 0.033034661838646097, 0.034783773471512389, 0.036258800113663003, 0.03770351802246065, 0.039365145766365024, 0.041341325796453957, 0.043771642465567313, 0.04646450771293998, 0.049542205415539955, 0.05292310665462082, 0.057531350136918818, 0.063701450508746663, 0.071740557125213808, 0.083136132331005669, 0.099461281924950698, 0.12422348654331426, 0.16581732923204678, 0.2492734632461393, 1.0])\n",
    "stock_allocations = pd.Series([0.81789336412001734, 0.81584538610764346, 0.81042750459597801, 0.80498948698905237, 0.79886688142970441, 0.79489911450757, 0.79154073305948436, 0.78390046690529824, 0.77651215459561385, 0.77651215255860817, 0.77086558886591372, 0.76476785202016995, 0.76048041386310017, 0.75627575076902154, 0.75205921164477696, 0.74476986724206617, 0.73971954666408557, 0.73565392891069636, 0.72994245336165653, 0.72523217620924729, 0.71995758485572614, 0.71535585193211471, 0.71022398451382318, 0.70527878142970934, 0.69984383409868922, 0.69518839294669621, 0.68999420117084576, 0.68496478242602588, 0.68006998425307064, 0.67503852649842844])\n",
    "\n",
    "model = SafeWithdrawalModel(returns_list = [real_stocks, real_bonds],\n",
    "                            names_list = [\"stocks\",\"bonds\"],\n",
    "                            allocations_list = [stock_allocations, bond_allocations],\n",
    "                            start_val = 100.0,\n",
    "                            const_spend = const_spend,\n",
    "                            var_spend_pcts = var_spend_pcts,\n",
    "                            gamma = 8.0,\n",
    "                            survival=None\n",
    ")\n",
    "\n",
    "# generate cohorts\n",
    "model.cohort_history = CohortHistory(model)\n",
    "\n",
    "print('%s Summary by cohort' % strftime(\"%H:%M:%S\"))\n",
    "print(model.cohort_history.as_dataframe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAF/CAYAAABKX7AhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3d3930890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_summary = model.cohort_history.summarize_by_year()\n",
    "df_years = model.cohort_history.spend_by_year()\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8, 6\n",
    "\n",
    "from matplotlib import colors\n",
    "mycolors =  list(colors.cnames)\n",
    "random.shuffle(mycolors)\n",
    "\n",
    "for ix in range(model.first_year, model.first_year + model.ret_cohorts):\n",
    "    plt.plot(df_years[str(ix)], linewidth=1, color=mycolors[ix-model.first_year], alpha=0.5, label='_nolegend_')\n",
    "\n",
    "\n",
    "plt.plot(df_summary.spend_mean, color='k', linewidth=2, label='Mean')\n",
    "plt.plot(df_summary.spend_max, color='g', linewidth=2, label='Best')\n",
    "plt.plot(df_summary.spend_min, color='r', linewidth=2, label='Worst')\n",
    "plt.plot(df_summary.spend_mean + df_summary.spend_sd, color='b', linewidth=1, label='+1 SD')\n",
    "plt.plot(df_summary.spend_mean - df_summary.spend_sd, color='b', linewidth=1, label='-1 SD')\n",
    "plt.fill_between(df_summary.index, df_summary.spend_mean + df_summary.spend_sd, \n",
    "                 df_summary.spend_mean - df_summary.spend_sd, color='blue', alpha='0.1')\n",
    "\n",
    "plt.ylabel(\"Annual spending as % of starting portfolio\")\n",
    "plt.xlabel(\"Retirement year\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=[0, 1])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const_spend</th>\n",
       "      <th>var_spend</th>\n",
       "      <th>stocks</th>\n",
       "      <th>bonds</th>\n",
       "      <th>spend_mean</th>\n",
       "      <th>spend_min</th>\n",
       "      <th>spend_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>2.203127</td>\n",
       "      <td>81.789336</td>\n",
       "      <td>18.210664</td>\n",
       "      <td>4.604840</td>\n",
       "      <td>3.724279</td>\n",
       "      <td>5.431478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>2.287617</td>\n",
       "      <td>81.584539</td>\n",
       "      <td>18.415461</td>\n",
       "      <td>4.731527</td>\n",
       "      <td>3.418391</td>\n",
       "      <td>6.254532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>2.349896</td>\n",
       "      <td>81.042750</td>\n",
       "      <td>18.957250</td>\n",
       "      <td>4.826188</td>\n",
       "      <td>3.513405</td>\n",
       "      <td>6.347958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>2.400992</td>\n",
       "      <td>80.498949</td>\n",
       "      <td>19.501051</td>\n",
       "      <td>4.932219</td>\n",
       "      <td>3.517121</td>\n",
       "      <td>7.302567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>2.457950</td>\n",
       "      <td>79.886688</td>\n",
       "      <td>20.113312</td>\n",
       "      <td>5.049210</td>\n",
       "      <td>3.505759</td>\n",
       "      <td>7.408146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>2.529678</td>\n",
       "      <td>79.489911</td>\n",
       "      <td>20.510089</td>\n",
       "      <td>5.197089</td>\n",
       "      <td>3.386326</td>\n",
       "      <td>7.941039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>2.606445</td>\n",
       "      <td>79.154073</td>\n",
       "      <td>20.845927</td>\n",
       "      <td>5.351562</td>\n",
       "      <td>3.420979</td>\n",
       "      <td>8.891322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>2.713869</td>\n",
       "      <td>78.390047</td>\n",
       "      <td>21.609953</td>\n",
       "      <td>5.557626</td>\n",
       "      <td>3.522455</td>\n",
       "      <td>9.081053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>2.836364</td>\n",
       "      <td>77.651215</td>\n",
       "      <td>22.348785</td>\n",
       "      <td>5.743047</td>\n",
       "      <td>3.348000</td>\n",
       "      <td>9.203257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>2.981631</td>\n",
       "      <td>77.651215</td>\n",
       "      <td>22.348785</td>\n",
       "      <td>5.980422</td>\n",
       "      <td>3.458124</td>\n",
       "      <td>10.540080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>3.137015</td>\n",
       "      <td>77.086559</td>\n",
       "      <td>22.913441</td>\n",
       "      <td>6.282104</td>\n",
       "      <td>3.425701</td>\n",
       "      <td>11.225243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>3.303466</td>\n",
       "      <td>76.476785</td>\n",
       "      <td>23.523215</td>\n",
       "      <td>6.610572</td>\n",
       "      <td>3.473727</td>\n",
       "      <td>11.643038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>3.478377</td>\n",
       "      <td>76.048041</td>\n",
       "      <td>23.951959</td>\n",
       "      <td>6.969665</td>\n",
       "      <td>3.317807</td>\n",
       "      <td>13.439483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>3.625880</td>\n",
       "      <td>75.627575</td>\n",
       "      <td>24.372425</td>\n",
       "      <td>7.310505</td>\n",
       "      <td>3.343283</td>\n",
       "      <td>15.059415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>3.770352</td>\n",
       "      <td>75.205921</td>\n",
       "      <td>24.794079</td>\n",
       "      <td>7.616833</td>\n",
       "      <td>3.459124</td>\n",
       "      <td>16.401976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>3.936515</td>\n",
       "      <td>74.476987</td>\n",
       "      <td>25.523013</td>\n",
       "      <td>7.908735</td>\n",
       "      <td>3.274292</td>\n",
       "      <td>17.074267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>4.134133</td>\n",
       "      <td>73.971955</td>\n",
       "      <td>26.028045</td>\n",
       "      <td>8.230050</td>\n",
       "      <td>3.366878</td>\n",
       "      <td>20.061546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>4.377164</td>\n",
       "      <td>73.565393</td>\n",
       "      <td>26.434607</td>\n",
       "      <td>8.588685</td>\n",
       "      <td>3.435252</td>\n",
       "      <td>22.118598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>4.646451</td>\n",
       "      <td>72.994245</td>\n",
       "      <td>27.005755</td>\n",
       "      <td>8.918598</td>\n",
       "      <td>3.395044</td>\n",
       "      <td>21.213925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>4.954221</td>\n",
       "      <td>72.523218</td>\n",
       "      <td>27.476782</td>\n",
       "      <td>9.251004</td>\n",
       "      <td>3.521019</td>\n",
       "      <td>21.152092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>5.292311</td>\n",
       "      <td>71.995758</td>\n",
       "      <td>28.004242</td>\n",
       "      <td>9.595167</td>\n",
       "      <td>3.708905</td>\n",
       "      <td>21.061695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>5.753135</td>\n",
       "      <td>71.535585</td>\n",
       "      <td>28.464415</td>\n",
       "      <td>10.053624</td>\n",
       "      <td>3.599248</td>\n",
       "      <td>20.643662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>6.370145</td>\n",
       "      <td>71.022398</td>\n",
       "      <td>28.977602</td>\n",
       "      <td>10.585032</td>\n",
       "      <td>3.637109</td>\n",
       "      <td>22.381867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>7.174056</td>\n",
       "      <td>70.527878</td>\n",
       "      <td>29.472122</td>\n",
       "      <td>11.207199</td>\n",
       "      <td>3.846862</td>\n",
       "      <td>23.833581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>8.313613</td>\n",
       "      <td>69.984383</td>\n",
       "      <td>30.015617</td>\n",
       "      <td>11.968715</td>\n",
       "      <td>3.682980</td>\n",
       "      <td>27.458563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>9.946128</td>\n",
       "      <td>69.518839</td>\n",
       "      <td>30.481161</td>\n",
       "      <td>12.956893</td>\n",
       "      <td>3.900901</td>\n",
       "      <td>29.879319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>12.422349</td>\n",
       "      <td>68.999420</td>\n",
       "      <td>31.000580</td>\n",
       "      <td>14.327986</td>\n",
       "      <td>3.908337</td>\n",
       "      <td>30.120498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>16.581733</td>\n",
       "      <td>68.496478</td>\n",
       "      <td>31.503522</td>\n",
       "      <td>16.463549</td>\n",
       "      <td>3.948743</td>\n",
       "      <td>35.387707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>24.927346</td>\n",
       "      <td>68.006998</td>\n",
       "      <td>31.993002</td>\n",
       "      <td>20.297396</td>\n",
       "      <td>3.750516</td>\n",
       "      <td>46.393183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.25168</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.503853</td>\n",
       "      <td>32.496147</td>\n",
       "      <td>54.071078</td>\n",
       "      <td>2.945589</td>\n",
       "      <td>135.483633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    const_spend   var_spend     stocks      bonds  spend_mean  spend_min  \\\n",
       "0       2.25168    2.203127  81.789336  18.210664    4.604840   3.724279   \n",
       "1       2.25168    2.287617  81.584539  18.415461    4.731527   3.418391   \n",
       "2       2.25168    2.349896  81.042750  18.957250    4.826188   3.513405   \n",
       "3       2.25168    2.400992  80.498949  19.501051    4.932219   3.517121   \n",
       "4       2.25168    2.457950  79.886688  20.113312    5.049210   3.505759   \n",
       "5       2.25168    2.529678  79.489911  20.510089    5.197089   3.386326   \n",
       "6       2.25168    2.606445  79.154073  20.845927    5.351562   3.420979   \n",
       "7       2.25168    2.713869  78.390047  21.609953    5.557626   3.522455   \n",
       "8       2.25168    2.836364  77.651215  22.348785    5.743047   3.348000   \n",
       "9       2.25168    2.981631  77.651215  22.348785    5.980422   3.458124   \n",
       "10      2.25168    3.137015  77.086559  22.913441    6.282104   3.425701   \n",
       "11      2.25168    3.303466  76.476785  23.523215    6.610572   3.473727   \n",
       "12      2.25168    3.478377  76.048041  23.951959    6.969665   3.317807   \n",
       "13      2.25168    3.625880  75.627575  24.372425    7.310505   3.343283   \n",
       "14      2.25168    3.770352  75.205921  24.794079    7.616833   3.459124   \n",
       "15      2.25168    3.936515  74.476987  25.523013    7.908735   3.274292   \n",
       "16      2.25168    4.134133  73.971955  26.028045    8.230050   3.366878   \n",
       "17      2.25168    4.377164  73.565393  26.434607    8.588685   3.435252   \n",
       "18      2.25168    4.646451  72.994245  27.005755    8.918598   3.395044   \n",
       "19      2.25168    4.954221  72.523218  27.476782    9.251004   3.521019   \n",
       "20      2.25168    5.292311  71.995758  28.004242    9.595167   3.708905   \n",
       "21      2.25168    5.753135  71.535585  28.464415   10.053624   3.599248   \n",
       "22      2.25168    6.370145  71.022398  28.977602   10.585032   3.637109   \n",
       "23      2.25168    7.174056  70.527878  29.472122   11.207199   3.846862   \n",
       "24      2.25168    8.313613  69.984383  30.015617   11.968715   3.682980   \n",
       "25      2.25168    9.946128  69.518839  30.481161   12.956893   3.900901   \n",
       "26      2.25168   12.422349  68.999420  31.000580   14.327986   3.908337   \n",
       "27      2.25168   16.581733  68.496478  31.503522   16.463549   3.948743   \n",
       "28      2.25168   24.927346  68.006998  31.993002   20.297396   3.750516   \n",
       "29      2.25168  100.000000  67.503853  32.496147   54.071078   2.945589   \n",
       "\n",
       "     spend_max  \n",
       "0     5.431478  \n",
       "1     6.254532  \n",
       "2     6.347958  \n",
       "3     7.302567  \n",
       "4     7.408146  \n",
       "5     7.941039  \n",
       "6     8.891322  \n",
       "7     9.081053  \n",
       "8     9.203257  \n",
       "9    10.540080  \n",
       "10   11.225243  \n",
       "11   11.643038  \n",
       "12   13.439483  \n",
       "13   15.059415  \n",
       "14   16.401976  \n",
       "15   17.074267  \n",
       "16   20.061546  \n",
       "17   22.118598  \n",
       "18   21.213925  \n",
       "19   21.152092  \n",
       "20   21.061695  \n",
       "21   20.643662  \n",
       "22   22.381867  \n",
       "23   23.833581  \n",
       "24   27.458563  \n",
       "25   29.879319  \n",
       "26   30.120498  \n",
       "27   35.387707  \n",
       "28   46.393183  \n",
       "29  135.483633  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary['const_spend'] = const_spend\n",
    "df_summary['var_spend'] = var_spend_pcts * 100\n",
    "df_summary['stocks'] = stock_allocations * 100\n",
    "df_summary['bonds'] = 100 - df_summary['stocks']\n",
    "cols = ['const_spend', 'var_spend', 'stocks', 'bonds', 'spend_mean', 'spend_min', 'spend_max']\n",
    "df_summary[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFwCAYAAAB3kDgfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3d38dac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_summary['var_spend'])\n",
    "plt.plot(df_summary['stocks'])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
